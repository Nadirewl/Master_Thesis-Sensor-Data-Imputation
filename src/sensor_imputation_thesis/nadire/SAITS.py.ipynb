{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to .venv (Python 3.10.16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ac258-ab28-428a-9f7a-167646032d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:31:13 [WARNING]: ‼️ PyPOTS Ecosystem configuration file does not exist.\n",
      "2025-05-20 12:31:13 [INFO]: Wrote new configs to config.ini successfully.\n",
      "2025-05-20 12:31:13 [INFO]: 💫 Initialized PyPOTS Ecosystem configuration file /home/ec2-user/.pypots/config.ini successfully.\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.3 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n",
      "Column time has 0 NaN values\n",
      "Column time has 0.0 Missing_rate\n",
      "Column fr_eng has 0 NaN values\n",
      "Column fr_eng has 0.0 Missing_rate\n",
      "Column te_exh_cyl_out__0 has 0 NaN values\n",
      "Column te_exh_cyl_out__0 has 0.0 Missing_rate\n",
      "Column pd_air_ic__0 has 0 NaN values\n",
      "Column pd_air_ic__0 has 0.0 Missing_rate\n",
      "Column pr_exh_turb_out__0 has 316581 NaN values\n",
      "Column pr_exh_turb_out__0 has 1.0 Missing_rate\n",
      "Column te_air_ic_out__0 has 0 NaN values\n",
      "Column te_air_ic_out__0 has 0.0 Missing_rate\n",
      "Column te_seawater has 0 NaN values\n",
      "Column te_seawater has 0.0 Missing_rate\n",
      "Column te_air_comp_in_a__0 has 316581 NaN values\n",
      "Column te_air_comp_in_a__0 has 1.0 Missing_rate\n",
      "Column te_air_comp_in_b__0 has 316581 NaN values\n",
      "Column te_air_comp_in_b__0 has 1.0 Missing_rate\n",
      "Column fr_tc__0 has 316581 NaN values\n",
      "Column fr_tc__0 has 1.0 Missing_rate\n",
      "Column pr_baro has 0 NaN values\n",
      "Column pr_baro has 0.0 Missing_rate\n",
      "Column pd_air_ic__0_1 has 0 NaN values\n",
      "Column pd_air_ic__0_1 has 0.0 Missing_rate\n",
      "Column pr_exh_rec has 0 NaN values\n",
      "Column pr_exh_rec has 0.0 Missing_rate\n",
      "Column te_exh_turb_in__0 has 316581 NaN values\n",
      "Column te_exh_turb_in__0 has 1.0 Missing_rate\n",
      "Column te_exh_turb_out__0 has 316581 NaN values\n",
      "Column te_exh_turb_out__0 has 1.0 Missing_rate\n",
      "Column bo_aux_blower_running has 0 NaN values\n",
      "Column bo_aux_blower_running has 0.0 Missing_rate\n",
      "Column re_eng_load has 426 NaN values\n",
      "Column re_eng_load has 0.0013456271854596453 Missing_rate\n",
      "Column pr_air_scav_ecs has 0 NaN values\n",
      "Column pr_air_scav_ecs has 0.0 Missing_rate\n",
      "Column pr_air_scav has 0 NaN values\n",
      "Column pr_air_scav has 0.0 Missing_rate\n",
      "Column te_air_scav_rec has 0 NaN values\n",
      "Column te_air_scav_rec has 0.0 Missing_rate\n",
      "Column te_air_ic_out__0_1 has 0 NaN values\n",
      "Column te_air_ic_out__0_1 has 0.0 Missing_rate\n",
      "Column pr_cyl_comp__0 has 426 NaN values\n",
      "Column pr_cyl_comp__0 has 0.0013456271854596453 Missing_rate\n",
      "Column pr_cyl_max__0 has 426 NaN values\n",
      "Column pr_cyl_max__0 has 0.0013456271854596453 Missing_rate\n",
      "Column se_mip__0 has 426 NaN values\n",
      "Column se_mip__0 has 0.0013456271854596453 Missing_rate\n",
      "Column te_exh_cyl_out__0_1 has 0 NaN values\n",
      "Column te_exh_cyl_out__0_1 has 0.0 Missing_rate\n",
      "Column fr_eng_setpoint has 0 NaN values\n",
      "Column fr_eng_setpoint has 0.0 Missing_rate\n",
      "Column te_air_scav_rec_iso has 126055 NaN values\n",
      "Column te_air_scav_rec_iso has 0.3981761381763277 Missing_rate\n",
      "Column pr_cyl_max_mv_iso has 128557 NaN values\n",
      "Column pr_cyl_max_mv_iso has 0.40607932882895686 Missing_rate\n",
      "Column pr_cyl_comp_mv_iso has 128557 NaN values\n",
      "Column pr_cyl_comp_mv_iso has 0.40607932882895686 Missing_rate\n",
      "Column fr_eng_ecs has 0 NaN values\n",
      "Column fr_eng_ecs has 0.0 Missing_rate\n",
      "Column pr_air_scav_iso has 128557 NaN values\n",
      "Column pr_air_scav_iso has 0.40607932882895686 Missing_rate\n",
      "Column engine_type_G80ME-C9.5-GI-LPSCR has 0 NaN values\n",
      "Column engine_type_G80ME-C9.5-GI-LPSCR has 0.0 Missing_rate\n",
      "Original size:316581, Sampled size: 105527\n",
      "Reshaped data:(105527, 31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/20 12:31:29 INFO mlflow.tracking.fluent: Experiment with name 'SAITS_2' does not exist. Creating a new experiment.\n",
      "2025/05/20 12:31:29 INFO mlflow.tracking.fluent: Experiment with name 'SAITS-2' does not exist. Creating a new experiment.\n",
      "[I 2025-05-20 12:31:29,860] A new study created in memory with name: no-name-bd0fbb77-ab84-4d60-9adb-d99753d60f5f\n",
      "2025-05-20 12:31:29 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:31:29 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123129\n",
      "2025-05-20 12:31:29 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123129/tensorboard\n",
      "2025-05-20 12:31:29 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:31:29 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:31:29 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=64\n",
      "2025-05-20 12:31:29 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:31:30 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 6,402,666\n",
      "2025-05-20 12:31:42 [INFO]: Epoch 001 - training loss (MAE): 0.2872, validation MSE: 0.2098\n",
      "2025-05-20 12:31:50 [INFO]: Epoch 002 - training loss (MAE): 0.1538, validation MSE: 0.1515\n",
      "2025-05-20 12:31:59 [INFO]: Epoch 003 - training loss (MAE): 0.1308, validation MSE: 0.1472\n",
      "2025-05-20 12:32:08 [INFO]: Epoch 004 - training loss (MAE): 0.1240, validation MSE: 0.1642\n",
      "2025-05-20 12:32:17 [INFO]: Epoch 005 - training loss (MAE): 0.1144, validation MSE: 0.1812\n",
      "2025-05-20 12:32:26 [INFO]: Epoch 006 - training loss (MAE): 0.1070, validation MSE: 0.4261\n",
      "2025-05-20 12:32:34 [INFO]: Epoch 007 - training loss (MAE): 0.1078, validation MSE: 0.4821\n",
      "2025-05-20 12:32:43 [INFO]: Epoch 008 - training loss (MAE): 0.1069, validation MSE: 0.2586\n",
      "2025-05-20 12:32:52 [INFO]: Epoch 009 - training loss (MAE): 0.1079, validation MSE: 0.3018\n",
      "2025-05-20 12:32:52 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:32:52 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 12:32:52 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123129/SAITS.pypots\n",
      "[W 2025-05-20 12:32:53,818] Trial 0 failed with parameters: {'n_layers': 2, 'd_model': 256, 'lr': 0.0009140680236796602, 'epochs': 15, 'batch_size': 7} because of the following error: NameError(\"name 'run' is not defined\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"<ipython-input-1-c04610e8c1c8>\", line 330, in objective\n",
      "    trial.set_user_attr(\"mlflow_run_id\", run.info.run_id)\n",
      "NameError: name 'run' is not defined\n",
      "[W 2025-05-20 12:32:53,821] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/512c8eb4f2944d00bc4ee2bdfe8e923d\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n",
      "🏃 View run SAITS_Optuna_Study at: http://localhost:5000/#/experiments/9/runs/2bbab57f67ca4e3a966d70fc4bdf2a87\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/SAITS.py:343\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39mstart_run(run_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSAITS_Optuna_Study\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m parent_run:\n\u001b[1;32m    342\u001b[0m     study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 343\u001b[0m     study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m)\n\u001b[1;32m    345\u001b[0m     best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams\n\u001b[1;32m    346\u001b[0m     best_value \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     _optimize(\n\u001b[1;32m    476\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    477\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    478\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    479\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    480\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    481\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    482\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    483\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    484\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m~/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[1;32m     64\u001b[0m             study,\n\u001b[1;32m     65\u001b[0m             func,\n\u001b[1;32m     66\u001b[0m             n_trials,\n\u001b[1;32m     67\u001b[0m             timeout,\n\u001b[1;32m     68\u001b[0m             catch,\n\u001b[1;32m     69\u001b[0m             callbacks,\n\u001b[1;32m     70\u001b[0m             gc_after_trial,\n\u001b[1;32m     71\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     72\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     73\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    198\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "File \u001b[1;32m/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/SAITS.py:330\u001b[0m\n\u001b[1;32m    327\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mavg_mae\u001b[39m\u001b[39m\"\u001b[39m, avg_mae)\n\u001b[1;32m    328\u001b[0m     mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mavg_rmse\u001b[39m\u001b[39m\"\u001b[39m, avg_rmse)\n\u001b[0;32m--> 330\u001b[0m     trial\u001b[39m.\u001b[39mset_user_attr(\u001b[39m\"\u001b[39m\u001b[39mmlflow_run_id\u001b[39m\u001b[39m\"\u001b[39m, run\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id)\n\u001b[1;32m    332\u001b[0m     \u001b[39mreturn\u001b[39;00m avg_mae\n\u001b[1;32m    334\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMAE per feature:\u001b[39m\u001b[39m\"\u001b[39m, mae_per_feature)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "#Import Pypots Library\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import SAITS\n",
    "#from pypots.utils.metrics import calc_mae\n",
    "from pypots.nn.functional import calc_mae\n",
    "\n",
    "\n",
    "import argparse\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import data_insight\n",
    "from data_insight import setup_duckdb\n",
    "from duckdb import DuckDBPyConnection as DuckDB\n",
    "from duckdb import DuckDBPyRelation as Relation\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "from duckdb import DuckDBPyConnection as DuckDB\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna \n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "from pygrinder.missing_completely_at_random import mcar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sensor_imputation_thesis.shared.load_data as load\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "#PatchTST might be an ideal choise if SAITS is too slow \n",
    "\n",
    "##Drop columns with different indexes while loading data.. Or the mean values \n",
    "\n",
    "df=pd.read_parquet(\"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/ny_df_for_pypots.parquet\")\n",
    "\n",
    "len(df)\n",
    "\n",
    "#current length of the dataframe is 119439\n",
    "\n",
    "# Check nan values in each column\n",
    "for col in df.columns:\n",
    "    print(f\"Column {col} has {df[col].isna().sum()} NaN values\")\n",
    "    missing_rate=df[col].isna().sum()/len(df[col])\n",
    "    print(f\"Column {col} has {missing_rate} Missing_rate\")\n",
    "\n",
    "\n",
    "#Try with smaller dataset, size 4000\n",
    "##SAMPLE the percengtage of the dataset, df.sample (averagely pick samples)\n",
    "#not df.sample cuz it will randomly select \n",
    "original_size=len(df)\n",
    "desired_fraction=0.3 #Select data every 3 minutes \n",
    "step=int(1/desired_fraction) #step_size=10 (sample every 10th (3/10) minute)\n",
    "\n",
    "#Systematic sampling: Start at a random offset to avoid bias \n",
    "start=np.random.randint(0,step) #Random start between 0-9\n",
    "df1=df.iloc[start::step].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original size:{len(df)}, Sampled size: {len(df1)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Custom Dataset class\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Data processing code\n",
    "sensor_cols = [col for col in df1.columns if col != \"time\"]\n",
    "data = df1[sensor_cols].values\n",
    "\n",
    "#¤get feature names for printing mae later \n",
    "feature_names=df1[sensor_cols].columns.tolist()\n",
    "\n",
    "## Convert data to 3D arrays of shape n_samples, n_timesteps, n_features, X_ori refers to the original data without missing values \n",
    "## Reconstruct all columns simultaneously  #num_features: 119\n",
    "n_features = data.shape[1]  # exclude the time column\n",
    "n_steps = 20 #60 (was 60 previously) #(TRY TO CHANGE HERE)  # # window length, 1440 steps = 24 hours of 1-minute data, but here is revised to 60 again\n",
    "#total_elements = data.shape[0] * data.shape[1]\n",
    "n_samples = data.shape[0] // n_steps \n",
    "\n",
    "\n",
    "\n",
    "# Reshape to (n_samples // n_steps, n_steps, n_features)\n",
    "#data_reshaped = data.reshape((n_samples, n_steps, n_features))\n",
    "data_reshaped=data[:n_samples*n_steps].reshape(n_samples,n_steps,n_features)\n",
    "print(f\"Reshaped data:{data.shape}\")\n",
    "\n",
    "#Split into train, test, val, fit scaler only on the train set (prevent data leakage)\n",
    "\n",
    "#train_size = int(0.6 * len(data))\n",
    "#val_size = int(0.2 * len(data))\n",
    "#test_size = len(data) - train_size - val_size\n",
    "\n",
    "#train_data = data_reshaped[:train_size]\n",
    "#val_data = data_reshaped[train_size:train_size + val_size]\n",
    "#test_data= data_reshaped[train_size + val_size:]\n",
    "\n",
    "\n",
    "#Apply time series split \n",
    "#Split into train(60%), val(20%), and test (20%)\n",
    "train_data, temp_data=train_test_split(data_reshaped,test_size=0.4,shuffle=True)\n",
    "val_data, test_data=train_test_split(temp_data, test_size=0.5, shuffle=False)\n",
    "\n",
    "##Normalization is important because of the nature of mse calculation of saits, columns with large \n",
    "#values dominate the loss, making metrics meaningless. SAITS computes MSE/MAE column-wise and averages \n",
    "#them across all columns \n",
    "#  Apply minmax scaler here \n",
    "#normalize each feature independently\n",
    "scalers={}\n",
    "\n",
    "\n",
    "#train_scaled = np.zeros_like(data_reshaped[train_size])  # Initialize the normalized data array\n",
    "#val_scaled=np.zeros_like(data_reshaped[train_size:train_size + val_size])\n",
    "#test_scaled=np.zeros_like(data_reshaped[train_size + val_size:])\n",
    "\n",
    "train_scaled = np.zeros_like(train_data)\n",
    "val_scaled = np.zeros_like(val_data)\n",
    "test_scaled = np.zeros_like(test_data)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(data_reshaped.shape[2]):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1)) #changed to -1,1\n",
    "    # Flatten timesteps and samples for scaling\n",
    "    train_scaled[:, :, i] = scaler.fit_transform(train_data[:, :, i].reshape(-1, 1)).reshape(train_data.shape[0], train_data.shape[1])\n",
    "    val_scaled[:, :, i] = scaler.transform(val_data[:, :, i].reshape(-1, 1)).reshape(val_data.shape[0], val_data.shape[1])\n",
    "    test_scaled[:, :, i] = scaler.transform(test_data[:, :, i].reshape(-1, 1)).reshape(test_data.shape[0], test_data.shape[1])\n",
    "    scalers[i] = scaler  # Save scalers to inverse-transform later\n",
    "\n",
    "#Inverse Scale\n",
    "def inverse_scale(imputation, scalers):\n",
    "    n_features = imputation.shape[2]\n",
    "    imputation_denorm = np.empty_like(imputation)\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        imputation_denorm[:, :, i] = scalers[i].inverse_transform(imputation[:, :, i].reshape(-1, 1)).reshape(imputation.shape[0], imputation.shape[1])\n",
    "    \n",
    "    return imputation_denorm  \n",
    "\n",
    "\n",
    "#Optional: Artificially mask. Mask 20% of the data (MIT part), try 30% to compare with GP-VAE\n",
    "def mcar_f(X, mask_ratio=0.3):\n",
    "    \"\"\"Apply MCAR only to observed values.\"\"\"\n",
    "    observed_mask=~np.isnan(X) #find observed positions\n",
    "    artificial_mask=mcar(X,mask_ratio).astype(bool) #generate MCAR mask, cast to boolean\n",
    "    #combine masks \n",
    "    combined_mask=observed_mask & artificial_mask\n",
    "\n",
    "    #Apply masking\n",
    "    X_masked=X.copy()\n",
    "    X_masked[combined_mask]=np.nan\n",
    "    return X_masked,combined_mask\n",
    "\n",
    "\n",
    "#Use mcar on validation data \n",
    "val_X_masked, val_mask =mcar_f(val_scaled)\n",
    "val_X_ori=val_scaled.copy() \n",
    "\n",
    "test_X_masked, test_mask =mcar_f(test_scaled)\n",
    "test_X_ori=test_scaled.copy() \n",
    "\n",
    "\n",
    "class Config:\n",
    "    no_cuda = False\n",
    "    no_mps = False\n",
    "    seed = 1\n",
    "\n",
    "args=Config()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "\n",
    "if args.cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "train_scaled = torch.tensor(train_scaled, dtype=torch.float32)\n",
    "val_X_masked = torch.tensor(val_X_masked, dtype=torch.float32)\n",
    "val_X_ori = torch.tensor(val_X_ori, dtype=torch.float32)\n",
    "\n",
    "train_scaled = train_scaled.to(device)\n",
    "val_X_masked = val_X_masked.to(device)\n",
    "val_X_ori = val_X_ori.to(device)\n",
    "\n",
    "\n",
    "#MLflow set up\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "mlflow.set_experiment(\"SAITS_2\")\n",
    "#SAITS_run_name = \"SAITS_1\"\n",
    "\n",
    "\n",
    "# Define comparison plot function\n",
    "\n",
    "def plot_comparison(original, masked, imputed, num_samples=3, num_features=3):\n",
    "    sample_indices = np.random.choice(original.shape[0], num_samples, replace=False)\n",
    "    feature_indices = np.random.choice(original.shape[2], num_features, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, num_features, figsize=(5 * num_features, 4 * num_samples))\n",
    "\n",
    "    for i, sample_idx in enumerate(sample_indices):\n",
    "        for j, feature_idx in enumerate(feature_indices):\n",
    "            ax = axes[i, j] if num_samples > 1 else axes[j]\n",
    "            ax.plot(original[sample_idx, :, feature_idx], label='Original', color='blue')\n",
    "            ax.plot(masked[sample_idx, :, feature_idx], label='Masked', color='orange', linestyle='dashed')\n",
    "            ax.plot(imputed[sample_idx, :, feature_idx], label='Imputed', color='green')\n",
    "            ax.set_title(f'Sample {sample_idx}, Feature {feature_idx}')\n",
    "            ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_layers\": trial.suggest_int(\"n_layers\", 2, 4),\n",
    "        \"d_model\": trial.suggest_categorical(\"d_model\", [64, 128, 256]),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 1e-3, log=True),\n",
    "        \"epochs\": trial.suggest_int(\"epochs\", 10, 20),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 16)\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(run_name=\"SAITS_testcomparedtoGPVAE\", nested=True):\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        saits = SAITS(\n",
    "            n_steps=data_reshaped.shape[1],\n",
    "            n_features=data_reshaped.shape[2],\n",
    "            n_layers=params[\"n_layers\"],\n",
    "            d_model=params[\"d_model\"],\n",
    "            optimizer=Adam(lr=params[\"lr\"]),\n",
    "            ORT_weight=1.0,\n",
    "            MIT_weight=1.0,\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            epochs=params[\"epochs\"],\n",
    "            d_ffn=512,\n",
    "            n_heads=8,\n",
    "            d_k=64,\n",
    "            d_v=64,\n",
    "            dropout=0.1,\n",
    "            attn_dropout=0.1,\n",
    "            diagonal_attention_mask=True,\n",
    "            patience=6,\n",
    "            num_workers=0,\n",
    "            device=device,\n",
    "            saving_path=\"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model\",\n",
    "            model_saving_strategy=\"best\",\n",
    "        )\n",
    "\n",
    "        saits.fit(train_set={\"X\": train_scaled}, val_set={\"X\": val_X_masked, \"X_ori\": val_X_ori})\n",
    "        test_imputation = saits.predict({\"X\": test_X_masked})[\"imputation\"]\n",
    "        test_imputation_denorm = inverse_scale(test_imputation, scalers)\n",
    "        test_ori_denorm = inverse_scale(test_X_ori, scalers)\n",
    "        \n",
    "\n",
    "           # Calculate metrics\n",
    "        mae_per_feature = []\n",
    "        rmse_per_feature=[]\n",
    "        percentage_mae_per_feature = []\n",
    "\n",
    "        for i in range(n_features):\n",
    "            imputation_i = test_imputation_denorm[:, :, i]\n",
    "            ground_truth_i = test_ori_denorm[:, :, i]\n",
    "            mask_i = test_mask[:, :, i]\n",
    "            if np.isnan(imputation_i).any() or np.isnan(ground_truth_i).any():\n",
    "                continue\n",
    "            mae_i = calc_mae(imputation_i, ground_truth_i, mask_i)\n",
    "            mae_per_feature.append(mae_i)\n",
    "            rmse_i = np.sqrt(mean_squared_error(imputation_i, ground_truth_i))\n",
    "            rmse_per_feature.append(rmse_i)\n",
    "\n",
    "            #Calculate the original standard deviation for the feature\n",
    "            std_dev_i = np.std(ground_truth_i[mask_i == 1])\n",
    "             # Calculate the percentage of MAE relative to the standard deviation   \n",
    "            if std_dev_i != 0:\n",
    "                percentage_mae_i = (mae_i / std_dev_i) * 100\n",
    "                percentage_mae_per_feature.append(percentage_mae_i)\n",
    "            else:\n",
    "                 percentage_mae_i = float('inf')\n",
    "            \n",
    "            mlflow.log_metric(f\"MAE_{feature_names[i]}\", mae_i)\n",
    "            mlflow.log_metric(f\"RMSE_{feature_names[i]}\",rmse_i)\n",
    "            mlflow.log_metric(f\"Percentage_MAE_{feature_names[i]}\", percentage_mae_i)\n",
    "\n",
    "        avg_mae = np.mean(mae_per_feature)\n",
    "        avg_rmse=np.mean(rmse_per_feature)\n",
    "       \n",
    "        mlflow.log_metric(\"avg_mae\", avg_mae)\n",
    "        mlflow.log_metric(\"avg_rmse\", avg_rmse)\n",
    "\n",
    "        trial.set_user_attr(\"mlflow_run_id\", run.info.run_id)\n",
    "\n",
    "        return avg_mae\n",
    "\n",
    "    print(\"MAE per feature:\", mae_per_feature)\n",
    "    print(\"RMSE per feature\",rmse_per_feature)\n",
    "    print(\"Percentage MAE per feature:\", percentage_mae_per_feature)\n",
    "   \n",
    "\n",
    "# Run Optuna study\n",
    "mlflow.set_experiment(\"SAITS-2\")\n",
    "with mlflow.start_run(run_name=\"SAITS_Optuna_Study\") as parent_run:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    best_params = study.best_trial.params\n",
    "    best_value = study.best_trial.value\n",
    "    best_run_id = study.best_trial.user_attrs[\"mlflow_run_id\"]\n",
    "       \n",
    "\n",
    "    # Log best parameters\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Log best metric(s)\n",
    "    mlflow.log_metric(\"best_objective_value\", best_value)\n",
    "    mlflow.log_param(\"best_run_id\", best_run_id)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Objective Value:\", best_value)\n",
    "\n",
    "\n",
    "\n",
    "# Re-run the model with best parameters\n",
    "saits_best = SAITS(\n",
    "    n_steps=data_reshaped.shape[1],\n",
    "    n_features=data_reshaped.shape[2],\n",
    "    n_layers=best_params[\"n_layers\"],\n",
    "    d_model=best_params[\"d_model\"],\n",
    "    optimizer=Adam(lr=best_params[\"lr\"]),\n",
    "    ORT_weight=1.0,\n",
    "    MIT_weight=1.0,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    d_ffn=512,\n",
    "    n_heads=8,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    attn_dropout=0.1,\n",
    "    diagonal_attention_mask=True,\n",
    "    patience=6,\n",
    "    num_workers=0,\n",
    "    device=device,\n",
    "    saving_path=\"...\",  # optional: path to save best model\n",
    "    model_saving_strategy=\"best\",\n",
    ")\n",
    "\n",
    "saits_best.fit(train_set={\"X\": train_scaled}, val_set={\"X\": val_X_masked, \"X_ori\": val_X_ori})\n",
    "test_imputation_best = saits_best.predict({\"X\": test_X_masked})[\"imputation\"]\n",
    "test_imputation_best_denorm = inverse_scale(test_imputation_best, scalers)\n",
    "test_ori_denorm = inverse_scale(test_X_ori, scalers)\n",
    "\n",
    "# Plot the comparison\n",
    "plot_comparison(test_ori_denorm, test_X_masked, test_imputation_best_denorm)\n",
    "###Till here!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c7df3-0a36-4a0c-85e2-debfe228107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column time has 0 NaN values\n",
      "Column time has 0.0 Missing_rate\n",
      "Column fr_eng has 0 NaN values\n",
      "Column fr_eng has 0.0 Missing_rate\n",
      "Column te_exh_cyl_out__0 has 0 NaN values\n",
      "Column te_exh_cyl_out__0 has 0.0 Missing_rate\n",
      "Column pd_air_ic__0 has 0 NaN values\n",
      "Column pd_air_ic__0 has 0.0 Missing_rate\n",
      "Column pr_exh_turb_out__0 has 316581 NaN values\n",
      "Column pr_exh_turb_out__0 has 1.0 Missing_rate\n",
      "Column te_air_ic_out__0 has 0 NaN values\n",
      "Column te_air_ic_out__0 has 0.0 Missing_rate\n",
      "Column te_seawater has 0 NaN values\n",
      "Column te_seawater has 0.0 Missing_rate\n",
      "Column te_air_comp_in_a__0 has 316581 NaN values\n",
      "Column te_air_comp_in_a__0 has 1.0 Missing_rate\n",
      "Column te_air_comp_in_b__0 has 316581 NaN values\n",
      "Column te_air_comp_in_b__0 has 1.0 Missing_rate\n",
      "Column fr_tc__0 has 316581 NaN values\n",
      "Column fr_tc__0 has 1.0 Missing_rate\n",
      "Column pr_baro has 0 NaN values\n",
      "Column pr_baro has 0.0 Missing_rate\n",
      "Column pd_air_ic__0_1 has 0 NaN values\n",
      "Column pd_air_ic__0_1 has 0.0 Missing_rate\n",
      "Column pr_exh_rec has 0 NaN values\n",
      "Column pr_exh_rec has 0.0 Missing_rate\n",
      "Column te_exh_turb_in__0 has 316581 NaN values\n",
      "Column te_exh_turb_in__0 has 1.0 Missing_rate\n",
      "Column te_exh_turb_out__0 has 316581 NaN values\n",
      "Column te_exh_turb_out__0 has 1.0 Missing_rate\n",
      "Column bo_aux_blower_running has 0 NaN values\n",
      "Column bo_aux_blower_running has 0.0 Missing_rate\n",
      "Column re_eng_load has 426 NaN values\n",
      "Column re_eng_load has 0.0013456271854596453 Missing_rate\n",
      "Column pr_air_scav_ecs has 0 NaN values\n",
      "Column pr_air_scav_ecs has 0.0 Missing_rate\n",
      "Column pr_air_scav has 0 NaN values\n",
      "Column pr_air_scav has 0.0 Missing_rate\n",
      "Column te_air_scav_rec has 0 NaN values\n",
      "Column te_air_scav_rec has 0.0 Missing_rate\n",
      "Column te_air_ic_out__0_1 has 0 NaN values\n",
      "Column te_air_ic_out__0_1 has 0.0 Missing_rate\n",
      "Column pr_cyl_comp__0 has 426 NaN values\n",
      "Column pr_cyl_comp__0 has 0.0013456271854596453 Missing_rate\n",
      "Column pr_cyl_max__0 has 426 NaN values\n",
      "Column pr_cyl_max__0 has 0.0013456271854596453 Missing_rate\n",
      "Column se_mip__0 has 426 NaN values\n",
      "Column se_mip__0 has 0.0013456271854596453 Missing_rate\n",
      "Column te_exh_cyl_out__0_1 has 0 NaN values\n",
      "Column te_exh_cyl_out__0_1 has 0.0 Missing_rate\n",
      "Column fr_eng_setpoint has 0 NaN values\n",
      "Column fr_eng_setpoint has 0.0 Missing_rate\n",
      "Column te_air_scav_rec_iso has 126055 NaN values\n",
      "Column te_air_scav_rec_iso has 0.3981761381763277 Missing_rate\n",
      "Column pr_cyl_max_mv_iso has 128557 NaN values\n",
      "Column pr_cyl_max_mv_iso has 0.40607932882895686 Missing_rate\n",
      "Column pr_cyl_comp_mv_iso has 128557 NaN values\n",
      "Column pr_cyl_comp_mv_iso has 0.40607932882895686 Missing_rate\n",
      "Column fr_eng_ecs has 0 NaN values\n",
      "Column fr_eng_ecs has 0.0 Missing_rate\n",
      "Column pr_air_scav_iso has 128557 NaN values\n",
      "Column pr_air_scav_iso has 0.40607932882895686 Missing_rate\n",
      "Column engine_type_G80ME-C9.5-GI-LPSCR has 0 NaN values\n",
      "Column engine_type_G80ME-C9.5-GI-LPSCR has 0.0 Missing_rate\n",
      "Original size:316581, Sampled size: 105527\n",
      "Reshaped data:(105527, 31)\n",
      "CUDA available: True\n",
      "Using CUDA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:776: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmin(X, axis=axis))\n",
      "/home/ec2-user/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/sklearn/utils/_array_api.py:793: RuntimeWarning: All-NaN slice encountered\n",
      "  return xp.asarray(numpy.nanmax(X, axis=axis))\n",
      "[I 2025-05-20 12:37:52,824] A new study created in memory with name: no-name-dcb1af14-3d45-45b0-a6d6-b9c218645b46\n",
      "2025-05-20 12:37:52 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:37:52 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123752\n",
      "2025-05-20 12:37:52 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123752/tensorboard\n",
      "2025-05-20 12:37:52 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:37:52 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:37:52 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=128, n_heads=8, d_k=64\n",
      "2025-05-20 12:37:52 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:37:52 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 6,402,666\n",
      "2025-05-20 12:37:57 [INFO]: Epoch 001 - training loss (MAE): 0.3109, validation MSE: 0.1551\n",
      "2025-05-20 12:38:01 [INFO]: Epoch 002 - training loss (MAE): 0.1462, validation MSE: 0.1528\n",
      "2025-05-20 12:38:06 [INFO]: Epoch 003 - training loss (MAE): 0.1168, validation MSE: 0.1509\n",
      "2025-05-20 12:38:10 [INFO]: Epoch 004 - training loss (MAE): 0.1067, validation MSE: 0.1694\n",
      "2025-05-20 12:38:16 [INFO]: Epoch 005 - training loss (MAE): 0.0927, validation MSE: 0.1764\n",
      "2025-05-20 12:38:20 [INFO]: Epoch 006 - training loss (MAE): 0.0854, validation MSE: 0.1552\n",
      "2025-05-20 12:38:25 [INFO]: Epoch 007 - training loss (MAE): 0.0806, validation MSE: 0.1627\n",
      "2025-05-20 12:38:29 [INFO]: Epoch 008 - training loss (MAE): 0.0756, validation MSE: 0.1771\n",
      "2025-05-20 12:38:33 [INFO]: Epoch 009 - training loss (MAE): 0.0715, validation MSE: 0.1827\n",
      "2025-05-20 12:38:33 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:38:33 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 12:38:33 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123752/SAITS.pypots\n",
      "[I 2025-05-20 12:38:35,114] Trial 0 finished with value: 7889.519350836137 and parameters: {'n_layers': 2, 'd_model': 128, 'lr': 0.0006287709598557443, 'epochs': 12, 'batch_size': 16}. Best is trial 0 with value: 7889.519350836137.\n",
      "2025-05-20 12:38:35 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:38:35 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123835\n",
      "2025-05-20 12:38:35 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123835/tensorboard\n",
      "2025-05-20 12:38:35 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:38:35 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:38:35 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=64\n",
      "2025-05-20 12:38:35 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:38:35 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 6,402,666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/ee55b28bd714433baa18a8a80a649525\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:38:41 [INFO]: Epoch 001 - training loss (MAE): 0.2999, validation MSE: 0.1477\n",
      "2025-05-20 12:38:47 [INFO]: Epoch 002 - training loss (MAE): 0.1716, validation MSE: 0.1565\n",
      "2025-05-20 12:38:53 [INFO]: Epoch 003 - training loss (MAE): 0.1389, validation MSE: 0.1510\n",
      "2025-05-20 12:38:59 [INFO]: Epoch 004 - training loss (MAE): 0.1213, validation MSE: 0.1529\n",
      "2025-05-20 12:39:05 [INFO]: Epoch 005 - training loss (MAE): 0.1073, validation MSE: 0.1510\n",
      "2025-05-20 12:39:11 [INFO]: Epoch 006 - training loss (MAE): 0.1007, validation MSE: 0.1533\n",
      "2025-05-20 12:39:17 [INFO]: Epoch 007 - training loss (MAE): 0.0943, validation MSE: 0.1551\n",
      "2025-05-20 12:39:17 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:39:17 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-05-20 12:39:17 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123835/SAITS.pypots\n",
      "[I 2025-05-20 12:39:18,390] Trial 1 finished with value: 7957.699467626767 and parameters: {'n_layers': 2, 'd_model': 256, 'lr': 0.00010069214525414646, 'epochs': 15, 'batch_size': 11}. Best is trial 0 with value: 7889.519350836137.\n",
      "2025-05-20 12:39:18 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:39:18 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123918\n",
      "2025-05-20 12:39:18 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123918/tensorboard\n",
      "2025-05-20 12:39:18 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:39:18 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:39:18 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 12:39:18 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:39:18 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 6,402,666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/a3d7c6a522bf4a858069fb1d7e696921\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:39:24 [INFO]: Epoch 001 - training loss (MAE): 0.2878, validation MSE: 0.1564\n",
      "2025-05-20 12:39:29 [INFO]: Epoch 002 - training loss (MAE): 0.1540, validation MSE: 0.1528\n",
      "2025-05-20 12:39:35 [INFO]: Epoch 003 - training loss (MAE): 0.1260, validation MSE: 0.1515\n",
      "2025-05-20 12:39:40 [INFO]: Epoch 004 - training loss (MAE): 0.1090, validation MSE: 0.1599\n",
      "2025-05-20 12:39:46 [INFO]: Epoch 005 - training loss (MAE): 0.0993, validation MSE: 0.3276\n",
      "2025-05-20 12:39:52 [INFO]: Epoch 006 - training loss (MAE): 0.0926, validation MSE: 0.1932\n",
      "2025-05-20 12:39:57 [INFO]: Epoch 007 - training loss (MAE): 0.0867, validation MSE: 0.1604\n",
      "2025-05-20 12:40:03 [INFO]: Epoch 008 - training loss (MAE): 0.0830, validation MSE: 0.1759\n",
      "2025-05-20 12:40:08 [INFO]: Epoch 009 - training loss (MAE): 0.0779, validation MSE: 0.2824\n",
      "2025-05-20 12:40:08 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:40:08 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 12:40:08 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T123918/SAITS.pypots\n",
      "[I 2025-05-20 12:40:10,214] Trial 2 finished with value: 7901.690888473103 and parameters: {'n_layers': 2, 'd_model': 64, 'lr': 0.0008346641398220421, 'epochs': 13, 'batch_size': 12}. Best is trial 0 with value: 7889.519350836137.\n",
      "2025-05-20 12:40:10 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:40:10 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124010\n",
      "2025-05-20 12:40:10 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124010/tensorboard\n",
      "2025-05-20 12:40:10 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:40:10 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:40:10 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 12:40:10 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:40:10 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 12,706,410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/bbe78e732d9b414da540b58a0d6da5cd\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:40:34 [INFO]: Epoch 001 - training loss (MAE): 0.5448, validation MSE: 0.1798\n",
      "2025-05-20 12:40:59 [INFO]: Epoch 002 - training loss (MAE): 0.5057, validation MSE: 0.1590\n",
      "2025-05-20 12:41:24 [INFO]: Epoch 003 - training loss (MAE): 0.5030, validation MSE: 0.1714\n",
      "2025-05-20 12:41:48 [INFO]: Epoch 004 - training loss (MAE): 0.5021, validation MSE: 0.1679\n",
      "2025-05-20 12:42:13 [INFO]: Epoch 005 - training loss (MAE): 0.5013, validation MSE: 0.1682\n",
      "2025-05-20 12:42:37 [INFO]: Epoch 006 - training loss (MAE): 0.5004, validation MSE: 0.1605\n",
      "2025-05-20 12:43:02 [INFO]: Epoch 007 - training loss (MAE): 0.5004, validation MSE: 0.1756\n",
      "2025-05-20 12:43:26 [INFO]: Epoch 008 - training loss (MAE): 0.4995, validation MSE: 0.1671\n",
      "2025-05-20 12:43:26 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:43:26 [INFO]: Finished training. The best model is from epoch#2.\n",
      "2025-05-20 12:43:26 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124010/SAITS.pypots\n",
      "[I 2025-05-20 12:43:29,428] Trial 3 finished with value: 7673.427720158439 and parameters: {'n_layers': 4, 'd_model': 64, 'lr': 0.0009882072417071277, 'epochs': 12, 'batch_size': 4}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:43:29 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:43:29 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124329\n",
      "2025-05-20 12:43:29 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124329/tensorboard\n",
      "2025-05-20 12:43:29 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:43:29 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:43:29 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=128, n_heads=8, d_k=64\n",
      "2025-05-20 12:43:29 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:43:29 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 6,402,666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/06ed3d546ae84680ba64f7f50ffc7c5a\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:43:34 [INFO]: Epoch 001 - training loss (MAE): 0.2867, validation MSE: 0.1657\n",
      "2025-05-20 12:43:38 [INFO]: Epoch 002 - training loss (MAE): 0.1645, validation MSE: 0.1755\n",
      "2025-05-20 12:43:43 [INFO]: Epoch 003 - training loss (MAE): 0.1371, validation MSE: 0.1669\n",
      "2025-05-20 12:43:48 [INFO]: Epoch 004 - training loss (MAE): 0.1191, validation MSE: 0.1701\n",
      "2025-05-20 12:43:52 [INFO]: Epoch 005 - training loss (MAE): 0.1055, validation MSE: 0.1601\n",
      "2025-05-20 12:43:57 [INFO]: Epoch 006 - training loss (MAE): 0.0969, validation MSE: 0.1610\n",
      "2025-05-20 12:44:02 [INFO]: Epoch 007 - training loss (MAE): 0.0916, validation MSE: 0.1603\n",
      "2025-05-20 12:44:06 [INFO]: Epoch 008 - training loss (MAE): 0.0860, validation MSE: 0.1532\n",
      "2025-05-20 12:44:11 [INFO]: Epoch 009 - training loss (MAE): 0.0831, validation MSE: 0.1577\n",
      "2025-05-20 12:44:16 [INFO]: Epoch 010 - training loss (MAE): 0.0794, validation MSE: 0.1602\n",
      "2025-05-20 12:44:20 [INFO]: Epoch 011 - training loss (MAE): 0.0769, validation MSE: 0.1697\n",
      "2025-05-20 12:44:25 [INFO]: Epoch 012 - training loss (MAE): 0.0730, validation MSE: 0.1634\n",
      "2025-05-20 12:44:29 [INFO]: Epoch 013 - training loss (MAE): 0.0711, validation MSE: 0.1687\n",
      "2025-05-20 12:44:34 [INFO]: Epoch 014 - training loss (MAE): 0.0690, validation MSE: 0.1764\n",
      "2025-05-20 12:44:34 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:44:34 [INFO]: Finished training. The best model is from epoch#8.\n",
      "2025-05-20 12:44:34 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124329/SAITS.pypots\n",
      "[I 2025-05-20 12:44:35,842] Trial 4 finished with value: 7868.069980257009 and parameters: {'n_layers': 2, 'd_model': 128, 'lr': 0.00013965255096375697, 'epochs': 19, 'batch_size': 15}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:44:35 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:44:35 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124435\n",
      "2025-05-20 12:44:35 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124435/tensorboard\n",
      "2025-05-20 12:44:35 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:44:35 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:44:35 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 12:44:35 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:44:35 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 9,554,538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/7cd01e69a5b24440a0c0948f72cadbbb\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:44:41 [INFO]: Epoch 001 - training loss (MAE): 0.3109, validation MSE: 0.1559\n",
      "2025-05-20 12:44:47 [INFO]: Epoch 002 - training loss (MAE): 0.1603, validation MSE: 0.1620\n",
      "2025-05-20 12:44:52 [INFO]: Epoch 003 - training loss (MAE): 0.1281, validation MSE: 0.1555\n",
      "2025-05-20 12:44:58 [INFO]: Epoch 004 - training loss (MAE): 0.1102, validation MSE: 0.1567\n",
      "2025-05-20 12:45:03 [INFO]: Epoch 005 - training loss (MAE): 0.0992, validation MSE: 0.1757\n",
      "2025-05-20 12:45:08 [INFO]: Epoch 006 - training loss (MAE): 0.0900, validation MSE: 0.1632\n",
      "2025-05-20 12:45:14 [INFO]: Epoch 007 - training loss (MAE): 0.0847, validation MSE: 0.1746\n",
      "2025-05-20 12:45:19 [INFO]: Epoch 008 - training loss (MAE): 0.0803, validation MSE: 0.1748\n",
      "2025-05-20 12:45:25 [INFO]: Epoch 009 - training loss (MAE): 0.0760, validation MSE: 0.1835\n",
      "2025-05-20 12:45:25 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:45:25 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 12:45:25 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124435/SAITS.pypots\n",
      "[I 2025-05-20 12:45:26,640] Trial 5 finished with value: 8298.086841776614 and parameters: {'n_layers': 3, 'd_model': 64, 'lr': 0.00032679420104273643, 'epochs': 20, 'batch_size': 16}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:45:26 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:45:26 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124526\n",
      "2025-05-20 12:45:26 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124526/tensorboard\n",
      "2025-05-20 12:45:26 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:45:26 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:45:26 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=64\n",
      "2025-05-20 12:45:26 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:45:26 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 9,554,538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/3884fc33e7cb4b5a8695d5f4c4125128\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:45:32 [INFO]: Epoch 001 - training loss (MAE): 0.3503, validation MSE: 0.2039\n",
      "2025-05-20 12:45:37 [INFO]: Epoch 002 - training loss (MAE): 0.1638, validation MSE: 0.1948\n",
      "2025-05-20 12:45:43 [INFO]: Epoch 003 - training loss (MAE): 0.1272, validation MSE: 0.2028\n",
      "2025-05-20 12:45:49 [INFO]: Epoch 004 - training loss (MAE): 0.1104, validation MSE: 0.1534\n",
      "2025-05-20 12:45:54 [INFO]: Epoch 005 - training loss (MAE): 0.0958, validation MSE: 0.1647\n",
      "2025-05-20 12:46:00 [INFO]: Epoch 006 - training loss (MAE): 0.0922, validation MSE: 0.2018\n",
      "2025-05-20 12:46:05 [INFO]: Epoch 007 - training loss (MAE): 0.0814, validation MSE: 0.2723\n",
      "2025-05-20 12:46:11 [INFO]: Epoch 008 - training loss (MAE): 0.0778, validation MSE: 0.3147\n",
      "2025-05-20 12:46:16 [INFO]: Epoch 009 - training loss (MAE): 0.0726, validation MSE: 0.2597\n",
      "2025-05-20 12:46:22 [INFO]: Epoch 010 - training loss (MAE): 0.0697, validation MSE: 0.1850\n",
      "2025-05-20 12:46:22 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:46:22 [INFO]: Finished training. The best model is from epoch#4.\n",
      "2025-05-20 12:46:22 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124526/SAITS.pypots\n",
      "[I 2025-05-20 12:46:23,842] Trial 6 finished with value: 7696.209863930574 and parameters: {'n_layers': 3, 'd_model': 256, 'lr': 0.0006428178669666378, 'epochs': 11, 'batch_size': 16}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:46:23 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:46:23 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124623\n",
      "2025-05-20 12:46:23 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124623/tensorboard\n",
      "2025-05-20 12:46:23 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:46:23 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:46:23 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=64\n",
      "2025-05-20 12:46:23 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:46:23 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 6,402,666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/3e0b39e9833742fda7d1c4920b209e04\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:46:31 [INFO]: Epoch 001 - training loss (MAE): 0.2467, validation MSE: 0.1857\n",
      "2025-05-20 12:46:38 [INFO]: Epoch 002 - training loss (MAE): 0.1404, validation MSE: 0.1662\n",
      "2025-05-20 12:46:45 [INFO]: Epoch 003 - training loss (MAE): 0.1135, validation MSE: 0.1598\n",
      "2025-05-20 12:46:52 [INFO]: Epoch 004 - training loss (MAE): 0.0984, validation MSE: 0.1697\n",
      "2025-05-20 12:47:00 [INFO]: Epoch 005 - training loss (MAE): 0.0882, validation MSE: 0.1719\n",
      "2025-05-20 12:47:07 [INFO]: Epoch 006 - training loss (MAE): 0.0834, validation MSE: 0.1656\n",
      "2025-05-20 12:47:15 [INFO]: Epoch 007 - training loss (MAE): 0.0796, validation MSE: 0.1809\n",
      "2025-05-20 12:47:22 [INFO]: Epoch 008 - training loss (MAE): 0.0735, validation MSE: 0.1742\n",
      "2025-05-20 12:47:29 [INFO]: Epoch 009 - training loss (MAE): 0.0687, validation MSE: 0.1830\n",
      "2025-05-20 12:47:29 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:47:29 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 12:47:29 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124623/SAITS.pypots\n",
      "[I 2025-05-20 12:47:30,473] Trial 7 finished with value: 7874.957188764333 and parameters: {'n_layers': 2, 'd_model': 256, 'lr': 0.00024455520421086803, 'epochs': 16, 'batch_size': 9}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:47:30 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:47:30 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124730\n",
      "2025-05-20 12:47:30 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124730/tensorboard\n",
      "2025-05-20 12:47:30 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:47:30 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:47:30 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=128, n_heads=8, d_k=64\n",
      "2025-05-20 12:47:30 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:47:30 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 6,402,666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/79606094361e44da8741bcf6fe6de2ae\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:47:37 [INFO]: Epoch 001 - training loss (MAE): 0.2578, validation MSE: 0.1598\n",
      "2025-05-20 12:47:43 [INFO]: Epoch 002 - training loss (MAE): 0.1477, validation MSE: 0.1539\n",
      "2025-05-20 12:47:50 [INFO]: Epoch 003 - training loss (MAE): 0.1182, validation MSE: 0.1497\n",
      "2025-05-20 12:47:56 [INFO]: Epoch 004 - training loss (MAE): 0.1051, validation MSE: 0.1562\n",
      "2025-05-20 12:48:03 [INFO]: Epoch 005 - training loss (MAE): 0.0954, validation MSE: 0.1681\n",
      "2025-05-20 12:48:09 [INFO]: Epoch 006 - training loss (MAE): 0.0889, validation MSE: 0.1826\n",
      "2025-05-20 12:48:15 [INFO]: Epoch 007 - training loss (MAE): 0.0832, validation MSE: 0.1726\n",
      "2025-05-20 12:48:22 [INFO]: Epoch 008 - training loss (MAE): 0.0782, validation MSE: 0.1753\n",
      "2025-05-20 12:48:28 [INFO]: Epoch 009 - training loss (MAE): 0.0733, validation MSE: 0.1853\n",
      "2025-05-20 12:48:28 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:48:28 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 12:48:28 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124730/SAITS.pypots\n",
      "[I 2025-05-20 12:48:30,093] Trial 8 finished with value: 7795.298896788495 and parameters: {'n_layers': 2, 'd_model': 128, 'lr': 0.000254191790560787, 'epochs': 20, 'batch_size': 10}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:48:30 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:48:30 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124830\n",
      "2025-05-20 12:48:30 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124830/tensorboard\n",
      "2025-05-20 12:48:30 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:48:30 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:48:30 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=64\n",
      "2025-05-20 12:48:30 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:48:30 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 6,402,666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/b02019c2b9054cbcb77f9f728da763cb\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:48:44 [INFO]: Epoch 001 - training loss (MAE): 0.2206, validation MSE: 0.1786\n",
      "2025-05-20 12:48:59 [INFO]: Epoch 002 - training loss (MAE): 0.1302, validation MSE: 0.1583\n",
      "2025-05-20 12:49:15 [INFO]: Epoch 003 - training loss (MAE): 0.1038, validation MSE: 0.1578\n",
      "2025-05-20 12:49:30 [INFO]: Epoch 004 - training loss (MAE): 0.0935, validation MSE: 0.1697\n",
      "2025-05-20 12:49:45 [INFO]: Epoch 005 - training loss (MAE): 0.0832, validation MSE: 0.1901\n",
      "2025-05-20 12:50:00 [INFO]: Epoch 006 - training loss (MAE): 0.0770, validation MSE: 0.2322\n",
      "2025-05-20 12:50:16 [INFO]: Epoch 007 - training loss (MAE): 0.0739, validation MSE: 0.2875\n",
      "2025-05-20 12:50:31 [INFO]: Epoch 008 - training loss (MAE): 0.0692, validation MSE: 0.1708\n",
      "2025-05-20 12:50:46 [INFO]: Epoch 009 - training loss (MAE): 0.0681, validation MSE: 0.5646\n",
      "2025-05-20 12:50:46 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:50:46 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 12:50:46 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T124830/SAITS.pypots\n",
      "[I 2025-05-20 12:50:49,055] Trial 9 finished with value: 7824.272360987509 and parameters: {'n_layers': 2, 'd_model': 256, 'lr': 0.0003837934355363417, 'epochs': 13, 'batch_size': 4}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:50:49 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:50:49 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125049\n",
      "2025-05-20 12:50:49 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125049/tensorboard\n",
      "2025-05-20 12:50:49 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:50:49 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:50:49 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 12:50:49 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:50:49 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 12,706,410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/4205822790cf4fd6ab6adf3a09ab319c\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:51:14 [INFO]: Epoch 001 - training loss (MAE): 0.5475, validation MSE: 0.1577\n",
      "2025-05-20 12:51:40 [INFO]: Epoch 002 - training loss (MAE): 0.5089, validation MSE: 0.1596\n",
      "2025-05-20 12:52:05 [INFO]: Epoch 003 - training loss (MAE): 0.5066, validation MSE: 0.1630\n",
      "2025-05-20 12:52:30 [INFO]: Epoch 004 - training loss (MAE): 0.5019, validation MSE: 0.1565\n",
      "2025-05-20 12:52:55 [INFO]: Epoch 005 - training loss (MAE): 0.4998, validation MSE: 0.1628\n",
      "2025-05-20 12:53:20 [INFO]: Epoch 006 - training loss (MAE): 0.5016, validation MSE: 0.1675\n",
      "2025-05-20 12:53:44 [INFO]: Epoch 007 - training loss (MAE): 0.5026, validation MSE: 0.1648\n",
      "2025-05-20 12:54:08 [INFO]: Epoch 008 - training loss (MAE): 0.4999, validation MSE: 0.1636\n",
      "2025-05-20 12:54:32 [INFO]: Epoch 009 - training loss (MAE): 0.4999, validation MSE: 0.1633\n",
      "2025-05-20 12:54:57 [INFO]: Epoch 010 - training loss (MAE): 0.4998, validation MSE: 0.1675\n",
      "2025-05-20 12:54:57 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:54:57 [INFO]: Finished training. The best model is from epoch#4.\n",
      "2025-05-20 12:54:57 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125049/SAITS.pypots\n",
      "[I 2025-05-20 12:55:00,146] Trial 10 finished with value: 7851.545892324103 and parameters: {'n_layers': 4, 'd_model': 64, 'lr': 0.000973746420467758, 'epochs': 10, 'batch_size': 4}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:55:00 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:55:00 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125500\n",
      "2025-05-20 12:55:00 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125500/tensorboard\n",
      "2025-05-20 12:55:00 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:55:00 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:55:00 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 12:55:00 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:55:00 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 12,706,410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/6e8388c2edcb440a9dd90cfd851804ea\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:55:14 [INFO]: Epoch 001 - training loss (MAE): 0.2905, validation MSE: 0.1563\n",
      "2025-05-20 12:55:28 [INFO]: Epoch 002 - training loss (MAE): 0.1619, validation MSE: 0.1627\n",
      "2025-05-20 12:55:42 [INFO]: Epoch 003 - training loss (MAE): 0.1423, validation MSE: 0.1760\n",
      "2025-05-20 12:55:56 [INFO]: Epoch 004 - training loss (MAE): 0.1261, validation MSE: 0.1632\n",
      "2025-05-20 12:56:10 [INFO]: Epoch 005 - training loss (MAE): 0.1278, validation MSE: 0.2225\n",
      "2025-05-20 12:56:25 [INFO]: Epoch 006 - training loss (MAE): 0.1307, validation MSE: 0.3550\n",
      "2025-05-20 12:56:40 [INFO]: Epoch 007 - training loss (MAE): 0.2227, validation MSE: 0.1545\n",
      "2025-05-20 12:56:54 [INFO]: Epoch 008 - training loss (MAE): 0.3874, validation MSE: 0.1564\n",
      "2025-05-20 12:57:08 [INFO]: Epoch 009 - training loss (MAE): 0.5194, validation MSE: 0.1645\n",
      "2025-05-20 12:57:23 [INFO]: Epoch 010 - training loss (MAE): 0.5153, validation MSE: 0.1685\n",
      "2025-05-20 12:57:23 [INFO]: Finished training. The best model is from epoch#7.\n",
      "2025-05-20 12:57:23 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125500/SAITS.pypots\n",
      "[I 2025-05-20 12:57:25,282] Trial 11 finished with value: 8177.311095100244 and parameters: {'n_layers': 4, 'd_model': 64, 'lr': 0.0005949227327081542, 'epochs': 10, 'batch_size': 7}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:57:25 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:57:25 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125725\n",
      "2025-05-20 12:57:25 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125725/tensorboard\n",
      "2025-05-20 12:57:25 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:57:25 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:57:25 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=256, n_heads=8, d_k=64\n",
      "2025-05-20 12:57:25 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:57:25 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 9,554,538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/69c1ef1ffb694f6fb9733e3ea640cae4\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:57:32 [INFO]: Epoch 001 - training loss (MAE): 0.2870, validation MSE: 0.1869\n",
      "2025-05-20 12:57:38 [INFO]: Epoch 002 - training loss (MAE): 0.1617, validation MSE: 0.1677\n",
      "2025-05-20 12:57:45 [INFO]: Epoch 003 - training loss (MAE): 0.1258, validation MSE: 0.1934\n",
      "2025-05-20 12:57:52 [INFO]: Epoch 004 - training loss (MAE): 0.1096, validation MSE: 0.1588\n",
      "2025-05-20 12:57:59 [INFO]: Epoch 005 - training loss (MAE): 0.0988, validation MSE: 0.2174\n",
      "2025-05-20 12:58:05 [INFO]: Epoch 006 - training loss (MAE): 0.0905, validation MSE: 0.3018\n",
      "2025-05-20 12:58:12 [INFO]: Epoch 007 - training loss (MAE): 0.0860, validation MSE: 0.2361\n",
      "2025-05-20 12:58:18 [INFO]: Epoch 008 - training loss (MAE): 0.0775, validation MSE: 0.2949\n",
      "2025-05-20 12:58:25 [INFO]: Epoch 009 - training loss (MAE): 0.0734, validation MSE: 0.2509\n",
      "2025-05-20 12:58:31 [INFO]: Epoch 010 - training loss (MAE): 0.0696, validation MSE: 0.3816\n",
      "2025-05-20 12:58:31 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 12:58:31 [INFO]: Finished training. The best model is from epoch#4.\n",
      "2025-05-20 12:58:32 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125725/SAITS.pypots\n",
      "[I 2025-05-20 12:58:33,774] Trial 12 finished with value: 7984.608958231025 and parameters: {'n_layers': 3, 'd_model': 256, 'lr': 0.0005712841413647365, 'epochs': 12, 'batch_size': 13}. Best is trial 3 with value: 7673.427720158439.\n",
      "2025-05-20 12:58:33 [INFO]: Using the given device: cuda\n",
      "2025-05-20 12:58:33 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125833\n",
      "2025-05-20 12:58:33 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125833/tensorboard\n",
      "2025-05-20 12:58:33 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 12:58:33 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 12:58:33 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 12:58:33 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 12:58:33 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 9,554,538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/0c19c57980b84ef9bf81f2ed89769fec\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 12:58:45 [INFO]: Epoch 001 - training loss (MAE): 0.5323, validation MSE: 0.1719\n",
      "2025-05-20 12:58:56 [INFO]: Epoch 002 - training loss (MAE): 0.5113, validation MSE: 0.1723\n",
      "2025-05-20 12:59:07 [INFO]: Epoch 003 - training loss (MAE): 0.5035, validation MSE: 0.1627\n",
      "2025-05-20 12:59:19 [INFO]: Epoch 004 - training loss (MAE): 0.5013, validation MSE: 0.1672\n",
      "2025-05-20 12:59:30 [INFO]: Epoch 005 - training loss (MAE): 0.5018, validation MSE: 0.1620\n",
      "2025-05-20 12:59:42 [INFO]: Epoch 006 - training loss (MAE): 0.5011, validation MSE: 0.1770\n",
      "2025-05-20 12:59:53 [INFO]: Epoch 007 - training loss (MAE): 0.5012, validation MSE: 0.1656\n",
      "2025-05-20 13:00:04 [INFO]: Epoch 008 - training loss (MAE): 0.5012, validation MSE: 0.1625\n",
      "2025-05-20 13:00:15 [INFO]: Epoch 009 - training loss (MAE): 0.5006, validation MSE: 0.1650\n",
      "2025-05-20 13:00:26 [INFO]: Epoch 010 - training loss (MAE): 0.4997, validation MSE: 0.1654\n",
      "2025-05-20 13:00:38 [INFO]: Epoch 011 - training loss (MAE): 0.5001, validation MSE: 0.1660\n",
      "2025-05-20 13:00:38 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 13:00:38 [INFO]: Finished training. The best model is from epoch#5.\n",
      "2025-05-20 13:00:38 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T125833/SAITS.pypots\n",
      "[I 2025-05-20 13:00:40,361] Trial 13 finished with value: 7663.0864225322075 and parameters: {'n_layers': 3, 'd_model': 64, 'lr': 0.000991619557792019, 'epochs': 11, 'batch_size': 7}. Best is trial 13 with value: 7663.0864225322075.\n",
      "2025-05-20 13:00:40 [INFO]: Using the given device: cuda\n",
      "2025-05-20 13:00:40 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130040\n",
      "2025-05-20 13:00:40 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130040/tensorboard\n",
      "2025-05-20 13:00:40 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 13:00:40 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 13:00:40 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 13:00:40 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 13:00:40 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 12,706,410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/6018c1e5c6f847079bf0dc2cfd4ec0fe\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:00:54 [INFO]: Epoch 001 - training loss (MAE): 0.5698, validation MSE: 0.1718\n",
      "2025-05-20 13:01:08 [INFO]: Epoch 002 - training loss (MAE): 0.5082, validation MSE: 0.1678\n",
      "2025-05-20 13:01:23 [INFO]: Epoch 003 - training loss (MAE): 0.5018, validation MSE: 0.1669\n",
      "2025-05-20 13:01:37 [INFO]: Epoch 004 - training loss (MAE): 0.4988, validation MSE: 0.1648\n",
      "2025-05-20 13:01:52 [INFO]: Epoch 005 - training loss (MAE): 0.5014, validation MSE: 0.1669\n",
      "2025-05-20 13:02:06 [INFO]: Epoch 006 - training loss (MAE): 0.5018, validation MSE: 0.1659\n",
      "2025-05-20 13:02:21 [INFO]: Epoch 007 - training loss (MAE): 0.4989, validation MSE: 0.1714\n",
      "2025-05-20 13:02:35 [INFO]: Epoch 008 - training loss (MAE): 0.4972, validation MSE: 0.1715\n",
      "2025-05-20 13:02:49 [INFO]: Epoch 009 - training loss (MAE): 0.4982, validation MSE: 0.1645\n",
      "2025-05-20 13:03:03 [INFO]: Epoch 010 - training loss (MAE): 0.4984, validation MSE: 0.1619\n",
      "2025-05-20 13:03:18 [INFO]: Epoch 011 - training loss (MAE): 0.4979, validation MSE: 0.1637\n",
      "2025-05-20 13:03:32 [INFO]: Epoch 012 - training loss (MAE): 0.4975, validation MSE: 0.1666\n",
      "2025-05-20 13:03:46 [INFO]: Epoch 013 - training loss (MAE): 0.4970, validation MSE: 0.1684\n",
      "2025-05-20 13:04:00 [INFO]: Epoch 014 - training loss (MAE): 0.4972, validation MSE: 0.1626\n",
      "2025-05-20 13:04:14 [INFO]: Epoch 015 - training loss (MAE): 0.4991, validation MSE: 0.1649\n",
      "2025-05-20 13:04:14 [INFO]: Finished training. The best model is from epoch#10.\n",
      "2025-05-20 13:04:14 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130040/SAITS.pypots\n",
      "[I 2025-05-20 13:04:17,287] Trial 14 finished with value: 7665.106454226625 and parameters: {'n_layers': 4, 'd_model': 64, 'lr': 0.0009898693310433687, 'epochs': 15, 'batch_size': 7}. Best is trial 13 with value: 7663.0864225322075.\n",
      "2025-05-20 13:04:17 [INFO]: Using the given device: cuda\n",
      "2025-05-20 13:04:17 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130417\n",
      "2025-05-20 13:04:17 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130417/tensorboard\n",
      "2025-05-20 13:04:17 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 13:04:17 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 13:04:17 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 13:04:17 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 13:04:17 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 9,554,538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/d008bad90ada45e69a050bfe24c61356\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:04:28 [INFO]: Epoch 001 - training loss (MAE): 0.2421, validation MSE: 0.2122\n",
      "2025-05-20 13:04:40 [INFO]: Epoch 002 - training loss (MAE): 0.1439, validation MSE: 0.1809\n",
      "2025-05-20 13:04:52 [INFO]: Epoch 003 - training loss (MAE): 0.1129, validation MSE: 0.1594\n",
      "2025-05-20 13:05:03 [INFO]: Epoch 004 - training loss (MAE): 0.0993, validation MSE: 0.2386\n",
      "2025-05-20 13:05:16 [INFO]: Epoch 005 - training loss (MAE): 0.0911, validation MSE: 0.2852\n",
      "2025-05-20 13:05:27 [INFO]: Epoch 006 - training loss (MAE): 0.0806, validation MSE: 0.1851\n",
      "2025-05-20 13:05:38 [INFO]: Epoch 007 - training loss (MAE): 0.0790, validation MSE: 0.4590\n",
      "2025-05-20 13:05:50 [INFO]: Epoch 008 - training loss (MAE): 0.0736, validation MSE: 0.2217\n",
      "2025-05-20 13:06:02 [INFO]: Epoch 009 - training loss (MAE): 0.0671, validation MSE: 0.6297\n",
      "2025-05-20 13:06:02 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 13:06:02 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 13:06:02 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130417/SAITS.pypots\n",
      "[I 2025-05-20 13:06:03,756] Trial 15 finished with value: 7995.992236698627 and parameters: {'n_layers': 3, 'd_model': 64, 'lr': 0.0004394159881248298, 'epochs': 17, 'batch_size': 7}. Best is trial 13 with value: 7663.0864225322075.\n",
      "2025-05-20 13:06:03 [INFO]: Using the given device: cuda\n",
      "2025-05-20 13:06:03 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130603\n",
      "2025-05-20 13:06:03 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130603/tensorboard\n",
      "2025-05-20 13:06:03 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 13:06:03 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 13:06:03 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 13:06:03 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 13:06:03 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 12,706,410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/ff953186fe934aa59bd032a91d328754\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:06:18 [INFO]: Epoch 001 - training loss (MAE): 0.4544, validation MSE: 0.1668\n",
      "2025-05-20 13:06:32 [INFO]: Epoch 002 - training loss (MAE): 0.2707, validation MSE: 0.1690\n",
      "2025-05-20 13:06:47 [INFO]: Epoch 003 - training loss (MAE): 0.2407, validation MSE: 0.1682\n",
      "2025-05-20 13:07:01 [INFO]: Epoch 004 - training loss (MAE): 0.2222, validation MSE: 0.1660\n",
      "2025-05-20 13:07:16 [INFO]: Epoch 005 - training loss (MAE): 0.2125, validation MSE: 0.1692\n",
      "2025-05-20 13:07:30 [INFO]: Epoch 006 - training loss (MAE): 0.2106, validation MSE: 0.1670\n",
      "2025-05-20 13:07:45 [INFO]: Epoch 007 - training loss (MAE): 0.2047, validation MSE: 0.1648\n",
      "2025-05-20 13:07:59 [INFO]: Epoch 008 - training loss (MAE): 0.1981, validation MSE: 0.1674\n",
      "2025-05-20 13:08:14 [INFO]: Epoch 009 - training loss (MAE): 0.2095, validation MSE: 0.1643\n",
      "2025-05-20 13:08:28 [INFO]: Epoch 010 - training loss (MAE): 0.2001, validation MSE: 0.1639\n",
      "2025-05-20 13:08:42 [INFO]: Epoch 011 - training loss (MAE): 0.1960, validation MSE: 0.1639\n",
      "2025-05-20 13:08:56 [INFO]: Epoch 012 - training loss (MAE): 0.1936, validation MSE: 0.1667\n",
      "2025-05-20 13:09:10 [INFO]: Epoch 013 - training loss (MAE): 0.1932, validation MSE: 0.1655\n",
      "2025-05-20 13:09:24 [INFO]: Epoch 014 - training loss (MAE): 0.1983, validation MSE: 0.1650\n",
      "2025-05-20 13:09:38 [INFO]: Epoch 015 - training loss (MAE): 0.2546, validation MSE: 0.1723\n",
      "2025-05-20 13:09:53 [INFO]: Epoch 016 - training loss (MAE): 0.4718, validation MSE: 0.1610\n",
      "2025-05-20 13:10:07 [INFO]: Epoch 017 - training loss (MAE): 0.4692, validation MSE: 0.1601\n",
      "2025-05-20 13:10:21 [INFO]: Epoch 018 - training loss (MAE): 0.4627, validation MSE: 0.1643\n",
      "2025-05-20 13:10:21 [INFO]: Finished training. The best model is from epoch#17.\n",
      "2025-05-20 13:10:21 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T130603/SAITS.pypots\n",
      "[I 2025-05-20 13:10:23,807] Trial 16 finished with value: 7786.517992772698 and parameters: {'n_layers': 4, 'd_model': 64, 'lr': 0.00078342448363653, 'epochs': 18, 'batch_size': 7}. Best is trial 13 with value: 7663.0864225322075.\n",
      "2025-05-20 13:10:23 [INFO]: Using the given device: cuda\n",
      "2025-05-20 13:10:23 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131023\n",
      "2025-05-20 13:10:23 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131023/tensorboard\n",
      "2025-05-20 13:10:23 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 13:10:23 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 13:10:23 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 13:10:23 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 13:10:23 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 9,554,538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/f9a2e2be852a47eb9d03acec2b61994e\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:10:37 [INFO]: Epoch 001 - training loss (MAE): 0.2548, validation MSE: 0.1598\n",
      "2025-05-20 13:10:50 [INFO]: Epoch 002 - training loss (MAE): 0.1497, validation MSE: 0.1547\n",
      "2025-05-20 13:11:03 [INFO]: Epoch 003 - training loss (MAE): 0.1265, validation MSE: 0.1499\n",
      "2025-05-20 13:11:18 [INFO]: Epoch 004 - training loss (MAE): 0.1123, validation MSE: 0.1994\n",
      "2025-05-20 13:11:31 [INFO]: Epoch 005 - training loss (MAE): 0.0975, validation MSE: 0.3450\n",
      "2025-05-20 13:11:44 [INFO]: Epoch 006 - training loss (MAE): 0.0909, validation MSE: 0.3001\n",
      "2025-05-20 13:11:57 [INFO]: Epoch 007 - training loss (MAE): 0.0834, validation MSE: 0.1741\n",
      "2025-05-20 13:12:10 [INFO]: Epoch 008 - training loss (MAE): 0.0791, validation MSE: 0.2002\n",
      "2025-05-20 13:12:24 [INFO]: Epoch 009 - training loss (MAE): 0.0754, validation MSE: 0.4751\n",
      "2025-05-20 13:12:24 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 13:12:24 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 13:12:24 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131023/SAITS.pypots\n",
      "[I 2025-05-20 13:12:26,174] Trial 17 finished with value: 7726.6144603841185 and parameters: {'n_layers': 3, 'd_model': 64, 'lr': 0.0004692272066187715, 'epochs': 14, 'batch_size': 6}. Best is trial 13 with value: 7663.0864225322075.\n",
      "2025-05-20 13:12:26 [INFO]: Using the given device: cuda\n",
      "2025-05-20 13:12:26 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131226\n",
      "2025-05-20 13:12:26 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131226/tensorboard\n",
      "2025-05-20 13:12:26 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 13:12:26 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 13:12:26 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 13:12:26 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 13:12:26 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 12,706,410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/b2acf72403824cd58c903e15ca3c2611\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:12:37 [INFO]: Epoch 001 - training loss (MAE): 0.2489, validation MSE: 0.1565\n",
      "2025-05-20 13:12:49 [INFO]: Epoch 002 - training loss (MAE): 0.1540, validation MSE: 0.1775\n",
      "2025-05-20 13:13:00 [INFO]: Epoch 003 - training loss (MAE): 0.1287, validation MSE: 0.1652\n",
      "2025-05-20 13:13:12 [INFO]: Epoch 004 - training loss (MAE): 0.1115, validation MSE: 0.1768\n",
      "2025-05-20 13:13:24 [INFO]: Epoch 005 - training loss (MAE): 0.1011, validation MSE: 0.2062\n",
      "2025-05-20 13:13:35 [INFO]: Epoch 006 - training loss (MAE): 0.0915, validation MSE: 0.1776\n",
      "2025-05-20 13:13:47 [INFO]: Epoch 007 - training loss (MAE): 0.0855, validation MSE: 0.1657\n",
      "2025-05-20 13:13:47 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 13:13:47 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-05-20 13:13:47 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131226/SAITS.pypots\n",
      "[I 2025-05-20 13:13:49,598] Trial 18 finished with value: 8234.718467055363 and parameters: {'n_layers': 4, 'd_model': 64, 'lr': 0.0001858756456503793, 'epochs': 15, 'batch_size': 9}. Best is trial 13 with value: 7663.0864225322075.\n",
      "2025-05-20 13:13:49 [INFO]: Using the given device: cuda\n",
      "2025-05-20 13:13:49 [INFO]: Model files will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131349\n",
      "2025-05-20 13:13:49 [INFO]: Tensorboard file will be saved to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131349/tensorboard\n",
      "2025-05-20 13:13:49 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 13:13:49 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 13:13:49 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 13:13:49 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 13:13:49 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 9,554,538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/b43fb8fc67fe4d278877e3a3ebcccf6d\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:14:03 [INFO]: Epoch 001 - training loss (MAE): 0.3106, validation MSE: 0.1562\n",
      "2025-05-20 13:14:16 [INFO]: Epoch 002 - training loss (MAE): 0.1784, validation MSE: 0.1901\n",
      "2025-05-20 13:14:30 [INFO]: Epoch 003 - training loss (MAE): 0.1459, validation MSE: 0.2281\n",
      "2025-05-20 13:14:43 [INFO]: Epoch 004 - training loss (MAE): 0.1501, validation MSE: 0.2678\n",
      "2025-05-20 13:14:57 [INFO]: Epoch 005 - training loss (MAE): 0.1458, validation MSE: 0.1657\n",
      "2025-05-20 13:15:10 [INFO]: Epoch 006 - training loss (MAE): 0.1587, validation MSE: 0.1800\n",
      "2025-05-20 13:15:24 [INFO]: Epoch 007 - training loss (MAE): 0.2551, validation MSE: 0.1929\n",
      "2025-05-20 13:15:24 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 13:15:24 [INFO]: Finished training. The best model is from epoch#1.\n",
      "2025-05-20 13:15:24 [INFO]: Saved the model to /home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model/20250520_T131349/SAITS.pypots\n",
      "[I 2025-05-20 13:15:27,220] Trial 19 finished with value: 8014.123164932668 and parameters: {'n_layers': 3, 'd_model': 64, 'lr': 0.0007796819924907747, 'epochs': 17, 'batch_size': 6}. Best is trial 13 with value: 7663.0864225322075.\n",
      "2025-05-20 13:15:27 [INFO]: Using the given device: cuda\n",
      "2025-05-20 13:15:27 [INFO]: Model files will be saved to .../20250520_T131527\n",
      "2025-05-20 13:15:27 [INFO]: Tensorboard file will be saved to .../20250520_T131527/tensorboard\n",
      "2025-05-20 13:15:27 [INFO]: Using customized MAE as the training loss function.\n",
      "2025-05-20 13:15:27 [INFO]: Using customized MSE as the validation metric function.\n",
      "2025-05-20 13:15:27 [WARNING]: ‼️ d_model must = n_heads * d_k, it should be divisible by n_heads and the result should be equal to d_k, but got d_model=64, n_heads=8, d_k=64\n",
      "2025-05-20 13:15:27 [WARNING]: ⚠️ d_model is reset to 512 = n_heads (8) * d_k (64)\n",
      "2025-05-20 13:15:27 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 9,554,538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run SAITS_testcomparedtoGPVAE at: http://localhost:5000/#/experiments/9/runs/8954f8756cc9471885ec0a68eea7feab\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n",
      "🏃 View run SAITS_Optuna_Study at: http://localhost:5000/#/experiments/9/runs/deb91e26635c482da1538dd697322df8\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/9\n",
      "Best Parameters: {'n_layers': 3, 'd_model': 64, 'lr': 0.000991619557792019, 'epochs': 11, 'batch_size': 7}\n",
      "Best Objective Value: 7663.0864225322075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 13:15:38 [INFO]: Epoch 001 - training loss (MAE): 0.3607, validation MSE: 0.1621\n",
      "2025-05-20 13:15:50 [INFO]: Epoch 002 - training loss (MAE): 0.2865, validation MSE: 0.3570\n",
      "2025-05-20 13:16:02 [INFO]: Epoch 003 - training loss (MAE): 0.4582, validation MSE: 0.1586\n",
      "2025-05-20 13:16:13 [INFO]: Epoch 004 - training loss (MAE): 0.5057, validation MSE: 0.1660\n",
      "2025-05-20 13:16:25 [INFO]: Epoch 005 - training loss (MAE): 0.5106, validation MSE: 0.1751\n",
      "2025-05-20 13:16:36 [INFO]: Epoch 006 - training loss (MAE): 0.5345, validation MSE: 0.1634\n",
      "2025-05-20 13:16:48 [INFO]: Epoch 007 - training loss (MAE): 0.5131, validation MSE: 0.1767\n",
      "2025-05-20 13:16:59 [INFO]: Epoch 008 - training loss (MAE): 0.5053, validation MSE: 0.1739\n",
      "2025-05-20 13:17:11 [INFO]: Epoch 009 - training loss (MAE): 0.5034, validation MSE: 0.1617\n",
      "2025-05-20 13:17:11 [INFO]: Exceeded the training patience. Terminating the training procedure...\n",
      "2025-05-20 13:17:11 [INFO]: Finished training. The best model is from epoch#3.\n",
      "2025-05-20 13:17:11 [INFO]: Saved the model to .../20250520_T131527/SAITS.pypots\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/comparison_plot.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/SAITS.py:395\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39m# Plot the comparison\u001b[39;00m\n\u001b[1;32m    394\u001b[0m save_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/comparison_plot.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 395\u001b[0m plot_comparison(test_ori_denorm, test_X_masked, test_imputation_best_denorm,save_path)\n",
      "File \u001b[1;32m/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/SAITS.py:235\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mplot_comparison\u001b[39m(original, masked, imputed, num_samples\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, num_features\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[0;32m--> 235\u001b[0m     sample_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mchoice(original\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m], num_samples, replace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    236\u001b[0m     feature_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mchoice(original\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], num_features, replace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    238\u001b[0m     fig, axes \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(num_samples, num_features, figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m \u001b[39m*\u001b[39m num_features, \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m num_samples))\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:982\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3100\u001b[0m, in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2979\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_prod_dispatcher)\n\u001b[1;32m   2980\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mprod\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[1;32m   2981\u001b[0m          initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[1;32m   2982\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2983\u001b[0m \u001b[39m    Return the product of array elements over a given axis.\u001b[39;00m\n\u001b[1;32m   2984\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3098\u001b[0m \u001b[39m    10\u001b[39;00m\n\u001b[1;32m   3099\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3100\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmultiply, \u001b[39m'\u001b[39;49m\u001b[39mprod\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out,\n\u001b[1;32m   3101\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/SageMaker/sensor-imputation-thesis/.venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:88\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> 88\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/comparison_plot.png'"
     ]
    }
   ],
   "source": [
    "#Import Pypots Library\n",
    "from pypots.optim import Adam\n",
    "from pypots.imputation import SAITS\n",
    "#from pypots.utils.metrics import calc_mae\n",
    "from pypots.nn.functional import calc_mae\n",
    "\n",
    "\n",
    "import argparse\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import data_insight\n",
    "from data_insight import setup_duckdb\n",
    "from duckdb import DuckDBPyConnection as DuckDB\n",
    "from duckdb import DuckDBPyRelation as Relation\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "from duckdb import DuckDBPyConnection as DuckDB\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna \n",
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, Dataset\n",
    "from pygrinder.missing_completely_at_random import mcar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import sensor_imputation_thesis.shared.load_data as load\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "#PatchTST might be an ideal choise if SAITS is too slow \n",
    "\n",
    "##Drop columns with different indexes while loading data.. Or the mean values \n",
    "\n",
    "df=pd.read_parquet(\"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/ny_df_for_pypots.parquet\")\n",
    "\n",
    "len(df)\n",
    "\n",
    "#current length of the dataframe is 119439\n",
    "\n",
    "# Check nan values in each column\n",
    "for col in df.columns:\n",
    "    print(f\"Column {col} has {df[col].isna().sum()} NaN values\")\n",
    "    missing_rate=df[col].isna().sum()/len(df[col])\n",
    "    print(f\"Column {col} has {missing_rate} Missing_rate\")\n",
    "\n",
    "\n",
    "#Try with smaller dataset, size 4000\n",
    "##SAMPLE the percengtage of the dataset, df.sample (averagely pick samples)\n",
    "#not df.sample cuz it will randomly select \n",
    "original_size=len(df)\n",
    "desired_fraction=0.3 #Select data every 3 minutes \n",
    "step=int(1/desired_fraction) #step_size=10 (sample every 10th (3/10) minute)\n",
    "\n",
    "#Systematic sampling: Start at a random offset to avoid bias \n",
    "start=np.random.randint(0,step) #Random start between 0-9\n",
    "df1=df.iloc[start::step].reset_index(drop=True)\n",
    "\n",
    "print(f\"Original size:{len(df)}, Sampled size: {len(df1)}\")\n",
    "\n",
    "\n",
    "\n",
    "# Custom Dataset class\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Data processing code\n",
    "sensor_cols = [col for col in df1.columns if col != \"time\"]\n",
    "data = df1[sensor_cols].values\n",
    "\n",
    "#¤get feature names for printing mae later \n",
    "feature_names=df1[sensor_cols].columns.tolist()\n",
    "\n",
    "## Convert data to 3D arrays of shape n_samples, n_timesteps, n_features, X_ori refers to the original data without missing values \n",
    "## Reconstruct all columns simultaneously  #num_features: 119\n",
    "n_features = data.shape[1]  # exclude the time column\n",
    "n_steps = 20 #60 (was 60 previously) #(TRY TO CHANGE HERE)  # # window length, 1440 steps = 24 hours of 1-minute data, but here is revised to 60 again\n",
    "#total_elements = data.shape[0] * data.shape[1]\n",
    "n_samples = data.shape[0] // n_steps \n",
    "\n",
    "\n",
    "\n",
    "# Reshape to (n_samples // n_steps, n_steps, n_features)\n",
    "#data_reshaped = data.reshape((n_samples, n_steps, n_features))\n",
    "data_reshaped=data[:n_samples*n_steps].reshape(n_samples,n_steps,n_features)\n",
    "print(f\"Reshaped data:{data.shape}\")\n",
    "\n",
    "#Split into train, test, val, fit scaler only on the train set (prevent data leakage)\n",
    "\n",
    "#train_size = int(0.6 * len(data))\n",
    "#val_size = int(0.2 * len(data))\n",
    "#test_size = len(data) - train_size - val_size\n",
    "\n",
    "#train_data = data_reshaped[:train_size]\n",
    "#val_data = data_reshaped[train_size:train_size + val_size]\n",
    "#test_data= data_reshaped[train_size + val_size:]\n",
    "\n",
    "\n",
    "#Apply time series split \n",
    "#Split into train(60%), val(20%), and test (20%)\n",
    "train_data, temp_data=train_test_split(data_reshaped,test_size=0.4,shuffle=True)\n",
    "val_data, test_data=train_test_split(temp_data, test_size=0.5, shuffle=False)\n",
    "\n",
    "##Normalization is important because of the nature of mse calculation of saits, columns with large \n",
    "#values dominate the loss, making metrics meaningless. SAITS computes MSE/MAE column-wise and averages \n",
    "#them across all columns \n",
    "#  Apply minmax scaler here \n",
    "#normalize each feature independently\n",
    "scalers={}\n",
    "\n",
    "\n",
    "#train_scaled = np.zeros_like(data_reshaped[train_size])  # Initialize the normalized data array\n",
    "#val_scaled=np.zeros_like(data_reshaped[train_size:train_size + val_size])\n",
    "#test_scaled=np.zeros_like(data_reshaped[train_size + val_size:])\n",
    "\n",
    "train_scaled = np.zeros_like(train_data)\n",
    "val_scaled = np.zeros_like(val_data)\n",
    "test_scaled = np.zeros_like(test_data)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(data_reshaped.shape[2]):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1)) #changed to -1,1\n",
    "    # Flatten timesteps and samples for scaling\n",
    "    train_scaled[:, :, i] = scaler.fit_transform(train_data[:, :, i].reshape(-1, 1)).reshape(train_data.shape[0], train_data.shape[1])\n",
    "    val_scaled[:, :, i] = scaler.transform(val_data[:, :, i].reshape(-1, 1)).reshape(val_data.shape[0], val_data.shape[1])\n",
    "    test_scaled[:, :, i] = scaler.transform(test_data[:, :, i].reshape(-1, 1)).reshape(test_data.shape[0], test_data.shape[1])\n",
    "    scalers[i] = scaler  # Save scalers to inverse-transform later\n",
    "\n",
    "#Inverse Scale\n",
    "def inverse_scale(imputation, scalers):\n",
    "    n_features = imputation.shape[2]\n",
    "    imputation_denorm = np.empty_like(imputation)\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        imputation_denorm[:, :, i] = scalers[i].inverse_transform(imputation[:, :, i].reshape(-1, 1)).reshape(imputation.shape[0], imputation.shape[1])\n",
    "    \n",
    "    return imputation_denorm  \n",
    "\n",
    "\n",
    "#Optional: Artificially mask. Mask 20% of the data (MIT part), try 30% to compare with GP-VAE\n",
    "def mcar_f(X, mask_ratio=0.3):\n",
    "    \"\"\"Apply MCAR only to observed values.\"\"\"\n",
    "    observed_mask=~np.isnan(X) #find observed positions\n",
    "    artificial_mask=mcar(X,mask_ratio).astype(bool) #generate MCAR mask, cast to boolean\n",
    "    #combine masks \n",
    "    combined_mask=observed_mask & artificial_mask\n",
    "\n",
    "    #Apply masking\n",
    "    X_masked=X.copy()\n",
    "    X_masked[combined_mask]=np.nan\n",
    "    return X_masked,combined_mask\n",
    "\n",
    "\n",
    "#Use mcar on validation data \n",
    "val_X_masked, val_mask =mcar_f(val_scaled)\n",
    "val_X_ori=val_scaled.copy() \n",
    "\n",
    "test_X_masked, test_mask =mcar_f(test_scaled)\n",
    "test_X_ori=test_scaled.copy() \n",
    "\n",
    "\n",
    "class Config:\n",
    "    no_cuda = False\n",
    "    no_mps = False\n",
    "    seed = 1\n",
    "\n",
    "args=Config()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "\n",
    "if args.cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "elif use_mps:\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "train_scaled = torch.tensor(train_scaled, dtype=torch.float32)\n",
    "val_X_masked = torch.tensor(val_X_masked, dtype=torch.float32)\n",
    "val_X_ori = torch.tensor(val_X_ori, dtype=torch.float32)\n",
    "\n",
    "train_scaled = train_scaled.to(device)\n",
    "val_X_masked = val_X_masked.to(device)\n",
    "val_X_ori = val_X_ori.to(device)\n",
    "\n",
    "\n",
    "#MLflow set up\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "mlflow.set_experiment(\"SAITS_2\")\n",
    "#SAITS_run_name = \"SAITS_1\"\n",
    "\n",
    "\n",
    "# Define comparison plot function\n",
    "\n",
    "def plot_comparison(original, masked, imputed, num_samples=3, num_features=3):\n",
    "    sample_indices = np.random.choice(original.shape[0], num_samples, replace=False)\n",
    "    feature_indices = np.random.choice(original.shape[2], num_features, replace=False)\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, num_features, figsize=(5 * num_features, 4 * num_samples))\n",
    "\n",
    "    for i, sample_idx in enumerate(sample_indices):\n",
    "        for j, feature_idx in enumerate(feature_indices):\n",
    "            ax = axes[i, j] if num_samples > 1 else axes[j]\n",
    "            ax.plot(original[sample_idx, :, feature_idx], label='Original', color='blue')\n",
    "            ax.plot(masked[sample_idx, :, feature_idx], label='Masked', color='orange', linestyle='dashed')\n",
    "            ax.plot(imputed[sample_idx, :, feature_idx], label='Imputed', color='green')\n",
    "            ax.set_title(f'Sample {sample_idx}, Feature {feature_idx}')\n",
    "            ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()\n",
    "\n",
    "# Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_layers\": trial.suggest_int(\"n_layers\", 2, 4),\n",
    "        \"d_model\": trial.suggest_categorical(\"d_model\", [64, 128, 256]),\n",
    "        \"lr\": trial.suggest_float(\"lr\", 1e-4, 1e-3, log=True),\n",
    "        \"epochs\": trial.suggest_int(\"epochs\", 10, 20),\n",
    "        \"batch_size\": trial.suggest_int(\"batch_size\", 4, 16)\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(run_name=\"SAITS_testcomparedtoGPVAE\", nested=True) as run:\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        saits = SAITS(\n",
    "            n_steps=data_reshaped.shape[1],\n",
    "            n_features=data_reshaped.shape[2],\n",
    "            n_layers=params[\"n_layers\"],\n",
    "            d_model=params[\"d_model\"],\n",
    "            optimizer=Adam(lr=params[\"lr\"]),\n",
    "            ORT_weight=1.0,\n",
    "            MIT_weight=1.0,\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            epochs=params[\"epochs\"],\n",
    "            d_ffn=512,\n",
    "            n_heads=8,\n",
    "            d_k=64,\n",
    "            d_v=64,\n",
    "            dropout=0.1,\n",
    "            attn_dropout=0.1,\n",
    "            diagonal_attention_mask=True,\n",
    "            patience=6,\n",
    "            num_workers=0,\n",
    "            device=device,\n",
    "            saving_path=\"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/best_model\",\n",
    "            model_saving_strategy=\"best\",\n",
    "        )\n",
    "\n",
    "        saits.fit(train_set={\"X\": train_scaled}, val_set={\"X\": val_X_masked, \"X_ori\": val_X_ori})\n",
    "        test_imputation = saits.predict({\"X\": test_X_masked})[\"imputation\"]\n",
    "        test_imputation_denorm = inverse_scale(test_imputation, scalers)\n",
    "        test_ori_denorm = inverse_scale(test_X_ori, scalers)\n",
    "        \n",
    "\n",
    "           # Calculate metrics\n",
    "        mae_per_feature = []\n",
    "        rmse_per_feature=[]\n",
    "        percentage_mae_per_feature = []\n",
    "\n",
    "        for i in range(n_features):\n",
    "            imputation_i = test_imputation_denorm[:, :, i]\n",
    "            ground_truth_i = test_ori_denorm[:, :, i]\n",
    "            mask_i = test_mask[:, :, i]\n",
    "            if np.isnan(imputation_i).any() or np.isnan(ground_truth_i).any():\n",
    "                continue\n",
    "            mae_i = calc_mae(imputation_i, ground_truth_i, mask_i)\n",
    "            mae_per_feature.append(mae_i)\n",
    "            rmse_i = np.sqrt(mean_squared_error(imputation_i, ground_truth_i))\n",
    "            rmse_per_feature.append(rmse_i)\n",
    "\n",
    "            #Calculate the original standard deviation for the feature\n",
    "            std_dev_i = np.std(ground_truth_i[mask_i == 1])\n",
    "             # Calculate the percentage of MAE relative to the standard deviation   \n",
    "            if std_dev_i != 0:\n",
    "                percentage_mae_i = (mae_i / std_dev_i) * 100\n",
    "                percentage_mae_per_feature.append(percentage_mae_i)\n",
    "            else:\n",
    "                 percentage_mae_i = float('inf')\n",
    "            \n",
    "            mlflow.log_metric(f\"MAE_{feature_names[i]}\", mae_i)\n",
    "            mlflow.log_metric(f\"RMSE_{feature_names[i]}\",rmse_i)\n",
    "            mlflow.log_metric(f\"Percentage_MAE_{feature_names[i]}\", percentage_mae_i)\n",
    "\n",
    "        avg_mae = np.mean(mae_per_feature)\n",
    "        avg_rmse=np.mean(rmse_per_feature)\n",
    "       \n",
    "        mlflow.log_metric(\"avg_mae\", avg_mae)\n",
    "        mlflow.log_metric(\"avg_rmse\", avg_rmse)\n",
    "\n",
    "        trial.set_user_attr(\"mlflow_run_id\", run.info.run_id)\n",
    "\n",
    "        return avg_mae\n",
    "\n",
    "    print(\"MAE per feature:\", mae_per_feature)\n",
    "    print(\"RMSE per feature\",rmse_per_feature)\n",
    "    print(\"Percentage MAE per feature:\", percentage_mae_per_feature)\n",
    "   \n",
    "\n",
    "# Run Optuna study\n",
    "mlflow.set_experiment(\"SAITS-2\")\n",
    "with mlflow.start_run(run_name=\"SAITS_Optuna_Study\") as parent_run:\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    best_params = study.best_trial.params\n",
    "    best_value = study.best_trial.value\n",
    "    best_run_id = study.best_trial.user_attrs[\"mlflow_run_id\"]\n",
    "       \n",
    "\n",
    "    # Log best parameters\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Log best metric(s)\n",
    "    mlflow.log_metric(\"best_objective_value\", best_value)\n",
    "    mlflow.log_param(\"best_run_id\", best_run_id)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Objective Value:\", best_value)\n",
    "\n",
    "\n",
    "\n",
    "# Re-run the model with best parameters\n",
    "saits_best = SAITS(\n",
    "    n_steps=data_reshaped.shape[1],\n",
    "    n_features=data_reshaped.shape[2],\n",
    "    n_layers=best_params[\"n_layers\"],\n",
    "    d_model=best_params[\"d_model\"],\n",
    "    optimizer=Adam(lr=best_params[\"lr\"]),\n",
    "    ORT_weight=1.0,\n",
    "    MIT_weight=1.0,\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    epochs=best_params[\"epochs\"],\n",
    "    d_ffn=512,\n",
    "    n_heads=8,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    attn_dropout=0.1,\n",
    "    diagonal_attention_mask=True,\n",
    "    patience=6,\n",
    "    num_workers=0,\n",
    "    device=device,\n",
    "    saving_path=\"...\",  # optional: path to save best model\n",
    "    model_saving_strategy=\"best\",\n",
    ")\n",
    "\n",
    "saits_best.fit(train_set={\"X\": train_scaled}, val_set={\"X\": val_X_masked, \"X_ori\": val_X_ori})\n",
    "test_imputation_best = saits_best.predict({\"X\": test_X_masked})[\"imputation\"]\n",
    "test_imputation_best_denorm = inverse_scale(test_imputation_best, scalers)\n",
    "test_ori_denorm = inverse_scale(test_X_ori, scalers)\n",
    "\n",
    "# Plot the comparison\n",
    "save_path = \"/home/ec2-user/SageMaker/sensor-imputation-thesis/src/sensor_imputation_thesis/nadire/comparison_plot.png\"\n",
    "plot_comparison(test_ori_denorm, test_X_masked, test_imputation_best_denorm,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'calculator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m calculator\n",
      "\u001b[0;31mNameError\u001b[0m: name 'calculator' is not defined"
     ]
    }
   ],
   "source": [
    "calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100000/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7053052591422315e-13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"te_seawater\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300       273.15\n",
       "301       273.15\n",
       "302       273.15\n",
       "303       273.15\n",
       "304       273.15\n",
       "           ...  \n",
       "438730    273.15\n",
       "438731    273.15\n",
       "438732    273.15\n",
       "438733    273.15\n",
       "438734    273.15\n",
       "Name: te_seawater, Length: 316581, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"te_seawater\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>fr_eng</th>\n",
       "      <th>te_exh_cyl_out__0</th>\n",
       "      <th>pd_air_ic__0</th>\n",
       "      <th>pr_exh_turb_out__0</th>\n",
       "      <th>te_air_ic_out__0</th>\n",
       "      <th>te_seawater</th>\n",
       "      <th>te_air_comp_in_a__0</th>\n",
       "      <th>te_air_comp_in_b__0</th>\n",
       "      <th>fr_tc__0</th>\n",
       "      <th>...</th>\n",
       "      <th>pr_cyl_max__0</th>\n",
       "      <th>se_mip__0</th>\n",
       "      <th>te_exh_cyl_out__0_1</th>\n",
       "      <th>fr_eng_setpoint</th>\n",
       "      <th>te_air_scav_rec_iso</th>\n",
       "      <th>pr_cyl_max_mv_iso</th>\n",
       "      <th>pr_cyl_comp_mv_iso</th>\n",
       "      <th>fr_eng_ecs</th>\n",
       "      <th>pr_air_scav_iso</th>\n",
       "      <th>engine_type_G80ME-C9.5-GI-LPSCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>316581</td>\n",
       "      <td>316581.000000</td>\n",
       "      <td>316581.000000</td>\n",
       "      <td>316581.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316581.000000</td>\n",
       "      <td>3.165810e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.161550e+05</td>\n",
       "      <td>3.161550e+05</td>\n",
       "      <td>316581.000000</td>\n",
       "      <td>316581.000000</td>\n",
       "      <td>190526.000000</td>\n",
       "      <td>1.880240e+05</td>\n",
       "      <td>1.880240e+05</td>\n",
       "      <td>316581.000000</td>\n",
       "      <td>188024.000000</td>\n",
       "      <td>316581.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2024-03-04 03:39:59.767831552</td>\n",
       "      <td>0.832841</td>\n",
       "      <td>529.816610</td>\n",
       "      <td>3110.918122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307.181012</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451855e+07</td>\n",
       "      <td>9.473236e+05</td>\n",
       "      <td>529.816610</td>\n",
       "      <td>0.832522</td>\n",
       "      <td>304.499911</td>\n",
       "      <td>1.456114e+07</td>\n",
       "      <td>1.077625e+07</td>\n",
       "      <td>0.832841</td>\n",
       "      <td>99833.635388</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2023-10-01 05:00:00</td>\n",
       "      <td>0.167429</td>\n",
       "      <td>319.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>293.350000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.837725e+06</td>\n",
       "      <td>-9.958676e+04</td>\n",
       "      <td>319.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>298.952784</td>\n",
       "      <td>4.026332e+06</td>\n",
       "      <td>4.055897e+06</td>\n",
       "      <td>0.167429</td>\n",
       "      <td>597.633930</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2023-12-12 22:19:00</td>\n",
       "      <td>0.777719</td>\n",
       "      <td>513.150000</td>\n",
       "      <td>1770.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305.850000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282315e+07</td>\n",
       "      <td>7.901175e+05</td>\n",
       "      <td>513.150000</td>\n",
       "      <td>0.778309</td>\n",
       "      <td>302.687664</td>\n",
       "      <td>1.300431e+07</td>\n",
       "      <td>9.346316e+06</td>\n",
       "      <td>0.777719</td>\n",
       "      <td>60194.674426</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2024-03-05 10:31:00</td>\n",
       "      <td>0.897132</td>\n",
       "      <td>542.150000</td>\n",
       "      <td>3290.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307.150000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.566857e+07</td>\n",
       "      <td>1.045047e+06</td>\n",
       "      <td>542.150000</td>\n",
       "      <td>0.899969</td>\n",
       "      <td>303.826959</td>\n",
       "      <td>1.551455e+07</td>\n",
       "      <td>1.157711e+07</td>\n",
       "      <td>0.897132</td>\n",
       "      <td>106705.193931</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2024-05-13 19:57:00</td>\n",
       "      <td>0.917471</td>\n",
       "      <td>553.150000</td>\n",
       "      <td>4370.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308.150000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.637930e+07</td>\n",
       "      <td>1.121625e+06</td>\n",
       "      <td>553.150000</td>\n",
       "      <td>0.916650</td>\n",
       "      <td>307.118440</td>\n",
       "      <td>1.628848e+07</td>\n",
       "      <td>1.227609e+07</td>\n",
       "      <td>0.917471</td>\n",
       "      <td>131549.740285</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-07-31 16:38:00</td>\n",
       "      <td>1.022311</td>\n",
       "      <td>597.150000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>318.750000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891545e+07</td>\n",
       "      <td>1.524548e+06</td>\n",
       "      <td>597.150000</td>\n",
       "      <td>1.016633</td>\n",
       "      <td>310.687664</td>\n",
       "      <td>1.909924e+07</td>\n",
       "      <td>1.560651e+07</td>\n",
       "      <td>1.022311</td>\n",
       "      <td>229136.394211</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142793</td>\n",
       "      <td>39.822783</td>\n",
       "      <td>1807.113916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.789116</td>\n",
       "      <td>1.705305e-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.561383e+06</td>\n",
       "      <td>2.658676e+05</td>\n",
       "      <td>39.822783</td>\n",
       "      <td>0.143734</td>\n",
       "      <td>2.474008</td>\n",
       "      <td>2.466624e+06</td>\n",
       "      <td>2.250869e+06</td>\n",
       "      <td>0.142793</td>\n",
       "      <td>52355.439774</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                time         fr_eng  te_exh_cyl_out__0  \\\n",
       "count                         316581  316581.000000      316581.000000   \n",
       "mean   2024-03-04 03:39:59.767831552       0.832841         529.816610   \n",
       "min              2023-10-01 05:00:00       0.167429         319.150000   \n",
       "25%              2023-12-12 22:19:00       0.777719         513.150000   \n",
       "50%              2024-03-05 10:31:00       0.897132         542.150000   \n",
       "75%              2024-05-13 19:57:00       0.917471         553.150000   \n",
       "max              2024-07-31 16:38:00       1.022311         597.150000   \n",
       "std                              NaN       0.142793          39.822783   \n",
       "\n",
       "        pd_air_ic__0  pr_exh_turb_out__0  te_air_ic_out__0   te_seawater  \\\n",
       "count  316581.000000                 0.0     316581.000000  3.165810e+05   \n",
       "mean     3110.918122                 NaN        307.181012  2.731500e+02   \n",
       "min         0.000000                 NaN        293.350000  2.731500e+02   \n",
       "25%      1770.000000                 NaN        305.850000  2.731500e+02   \n",
       "50%      3290.000000                 NaN        307.150000  2.731500e+02   \n",
       "75%      4370.000000                 NaN        308.150000  2.731500e+02   \n",
       "max     10000.000000                 NaN        318.750000  2.731500e+02   \n",
       "std      1807.113916                 NaN          1.789116  1.705305e-13   \n",
       "\n",
       "       te_air_comp_in_a__0  te_air_comp_in_b__0  fr_tc__0  ...  pr_cyl_max__0  \\\n",
       "count                  0.0                  0.0       0.0  ...   3.161550e+05   \n",
       "mean                   NaN                  NaN       NaN  ...   1.451855e+07   \n",
       "min                    NaN                  NaN       NaN  ...   3.837725e+06   \n",
       "25%                    NaN                  NaN       NaN  ...   1.282315e+07   \n",
       "50%                    NaN                  NaN       NaN  ...   1.566857e+07   \n",
       "75%                    NaN                  NaN       NaN  ...   1.637930e+07   \n",
       "max                    NaN                  NaN       NaN  ...   1.891545e+07   \n",
       "std                    NaN                  NaN       NaN  ...   2.561383e+06   \n",
       "\n",
       "          se_mip__0  te_exh_cyl_out__0_1  fr_eng_setpoint  \\\n",
       "count  3.161550e+05        316581.000000    316581.000000   \n",
       "mean   9.473236e+05           529.816610         0.832522   \n",
       "min   -9.958676e+04           319.150000         0.000000   \n",
       "25%    7.901175e+05           513.150000         0.778309   \n",
       "50%    1.045047e+06           542.150000         0.899969   \n",
       "75%    1.121625e+06           553.150000         0.916650   \n",
       "max    1.524548e+06           597.150000         1.016633   \n",
       "std    2.658676e+05            39.822783         0.143734   \n",
       "\n",
       "       te_air_scav_rec_iso  pr_cyl_max_mv_iso  pr_cyl_comp_mv_iso  \\\n",
       "count        190526.000000       1.880240e+05        1.880240e+05   \n",
       "mean            304.499911       1.456114e+07        1.077625e+07   \n",
       "min             298.952784       4.026332e+06        4.055897e+06   \n",
       "25%             302.687664       1.300431e+07        9.346316e+06   \n",
       "50%             303.826959       1.551455e+07        1.157711e+07   \n",
       "75%             307.118440       1.628848e+07        1.227609e+07   \n",
       "max             310.687664       1.909924e+07        1.560651e+07   \n",
       "std               2.474008       2.466624e+06        2.250869e+06   \n",
       "\n",
       "          fr_eng_ecs  pr_air_scav_iso  engine_type_G80ME-C9.5-GI-LPSCR  \n",
       "count  316581.000000    188024.000000                         316581.0  \n",
       "mean        0.832841     99833.635388                              1.0  \n",
       "min         0.167429       597.633930                              1.0  \n",
       "25%         0.777719     60194.674426                              1.0  \n",
       "50%         0.897132    106705.193931                              1.0  \n",
       "75%         0.917471    131549.740285                              1.0  \n",
       "max         1.022311    229136.394211                              1.0  \n",
       "std         0.142793     52355.439774                              0.0  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>fr_eng</th>\n",
       "      <th>te_exh_cyl_out__0</th>\n",
       "      <th>pd_air_ic__0</th>\n",
       "      <th>pr_exh_turb_out__0</th>\n",
       "      <th>te_air_ic_out__0</th>\n",
       "      <th>te_seawater</th>\n",
       "      <th>te_air_comp_in_a__0</th>\n",
       "      <th>te_air_comp_in_b__0</th>\n",
       "      <th>fr_tc__0</th>\n",
       "      <th>...</th>\n",
       "      <th>pr_cyl_max__0</th>\n",
       "      <th>se_mip__0</th>\n",
       "      <th>te_exh_cyl_out__0_1</th>\n",
       "      <th>fr_eng_setpoint</th>\n",
       "      <th>te_air_scav_rec_iso</th>\n",
       "      <th>pr_cyl_max_mv_iso</th>\n",
       "      <th>pr_cyl_comp_mv_iso</th>\n",
       "      <th>fr_eng_ecs</th>\n",
       "      <th>pr_air_scav_iso</th>\n",
       "      <th>engine_type_G80ME-C9.5-GI-LPSCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>105527</td>\n",
       "      <td>105527.000000</td>\n",
       "      <td>105527.000000</td>\n",
       "      <td>105527.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105527.000000</td>\n",
       "      <td>1.055270e+05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053750e+05</td>\n",
       "      <td>1.053750e+05</td>\n",
       "      <td>105527.000000</td>\n",
       "      <td>105527.000000</td>\n",
       "      <td>63500.000000</td>\n",
       "      <td>6.266600e+04</td>\n",
       "      <td>6.266600e+04</td>\n",
       "      <td>105527.000000</td>\n",
       "      <td>62666.000000</td>\n",
       "      <td>105527.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2024-03-04 03:39:57.460175872</td>\n",
       "      <td>0.832848</td>\n",
       "      <td>529.814569</td>\n",
       "      <td>3111.361926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307.180843</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451877e+07</td>\n",
       "      <td>9.473490e+05</td>\n",
       "      <td>529.814569</td>\n",
       "      <td>0.832521</td>\n",
       "      <td>304.499043</td>\n",
       "      <td>1.456122e+07</td>\n",
       "      <td>1.077643e+07</td>\n",
       "      <td>0.832848</td>\n",
       "      <td>99836.699333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2023-10-01 05:01:00</td>\n",
       "      <td>0.167429</td>\n",
       "      <td>321.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>293.350000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.837725e+06</td>\n",
       "      <td>-9.958676e+04</td>\n",
       "      <td>321.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>298.952784</td>\n",
       "      <td>4.027020e+06</td>\n",
       "      <td>4.056834e+06</td>\n",
       "      <td>0.167429</td>\n",
       "      <td>3098.270339</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2023-12-12 22:19:30</td>\n",
       "      <td>0.777576</td>\n",
       "      <td>513.150000</td>\n",
       "      <td>1770.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>305.850000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.282562e+07</td>\n",
       "      <td>7.904133e+05</td>\n",
       "      <td>513.150000</td>\n",
       "      <td>0.778309</td>\n",
       "      <td>302.687664</td>\n",
       "      <td>1.300006e+07</td>\n",
       "      <td>9.345829e+06</td>\n",
       "      <td>0.777576</td>\n",
       "      <td>60206.960626</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2024-03-05 10:31:00</td>\n",
       "      <td>0.897077</td>\n",
       "      <td>542.150000</td>\n",
       "      <td>3290.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>307.150000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.566906e+07</td>\n",
       "      <td>1.045234e+06</td>\n",
       "      <td>542.150000</td>\n",
       "      <td>0.899969</td>\n",
       "      <td>303.826959</td>\n",
       "      <td>1.551538e+07</td>\n",
       "      <td>1.157662e+07</td>\n",
       "      <td>0.897077</td>\n",
       "      <td>106687.706718</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2024-05-13 19:56:30</td>\n",
       "      <td>0.917473</td>\n",
       "      <td>553.150000</td>\n",
       "      <td>4370.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308.150000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.637984e+07</td>\n",
       "      <td>1.121550e+06</td>\n",
       "      <td>553.150000</td>\n",
       "      <td>0.916647</td>\n",
       "      <td>307.118440</td>\n",
       "      <td>1.628844e+07</td>\n",
       "      <td>1.227628e+07</td>\n",
       "      <td>0.917473</td>\n",
       "      <td>131524.664414</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-07-31 16:37:00</td>\n",
       "      <td>1.020961</td>\n",
       "      <td>597.150000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317.350000</td>\n",
       "      <td>2.731500e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.891545e+07</td>\n",
       "      <td>1.524548e+06</td>\n",
       "      <td>597.150000</td>\n",
       "      <td>1.016633</td>\n",
       "      <td>310.687664</td>\n",
       "      <td>1.909924e+07</td>\n",
       "      <td>1.560651e+07</td>\n",
       "      <td>1.020961</td>\n",
       "      <td>227660.755509</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142778</td>\n",
       "      <td>39.830309</td>\n",
       "      <td>1805.671624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.788752</td>\n",
       "      <td>5.684369e-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.561205e+06</td>\n",
       "      <td>2.658468e+05</td>\n",
       "      <td>39.830309</td>\n",
       "      <td>0.143739</td>\n",
       "      <td>2.473322</td>\n",
       "      <td>2.465755e+06</td>\n",
       "      <td>2.250138e+06</td>\n",
       "      <td>0.142778</td>\n",
       "      <td>52343.895098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                time         fr_eng  te_exh_cyl_out__0  \\\n",
       "count                         105527  105527.000000      105527.000000   \n",
       "mean   2024-03-04 03:39:57.460175872       0.832848         529.814569   \n",
       "min              2023-10-01 05:01:00       0.167429         321.150000   \n",
       "25%              2023-12-12 22:19:30       0.777576         513.150000   \n",
       "50%              2024-03-05 10:31:00       0.897077         542.150000   \n",
       "75%              2024-05-13 19:56:30       0.917473         553.150000   \n",
       "max              2024-07-31 16:37:00       1.020961         597.150000   \n",
       "std                              NaN       0.142778          39.830309   \n",
       "\n",
       "        pd_air_ic__0  pr_exh_turb_out__0  te_air_ic_out__0   te_seawater  \\\n",
       "count  105527.000000                 0.0     105527.000000  1.055270e+05   \n",
       "mean     3111.361926                 NaN        307.180843  2.731500e+02   \n",
       "min         0.000000                 NaN        293.350000  2.731500e+02   \n",
       "25%      1770.000000                 NaN        305.850000  2.731500e+02   \n",
       "50%      3290.000000                 NaN        307.150000  2.731500e+02   \n",
       "75%      4370.000000                 NaN        308.150000  2.731500e+02   \n",
       "max     10000.000000                 NaN        317.350000  2.731500e+02   \n",
       "std      1805.671624                 NaN          1.788752  5.684369e-14   \n",
       "\n",
       "       te_air_comp_in_a__0  te_air_comp_in_b__0  fr_tc__0  ...  pr_cyl_max__0  \\\n",
       "count                  0.0                  0.0       0.0  ...   1.053750e+05   \n",
       "mean                   NaN                  NaN       NaN  ...   1.451877e+07   \n",
       "min                    NaN                  NaN       NaN  ...   3.837725e+06   \n",
       "25%                    NaN                  NaN       NaN  ...   1.282562e+07   \n",
       "50%                    NaN                  NaN       NaN  ...   1.566906e+07   \n",
       "75%                    NaN                  NaN       NaN  ...   1.637984e+07   \n",
       "max                    NaN                  NaN       NaN  ...   1.891545e+07   \n",
       "std                    NaN                  NaN       NaN  ...   2.561205e+06   \n",
       "\n",
       "          se_mip__0  te_exh_cyl_out__0_1  fr_eng_setpoint  \\\n",
       "count  1.053750e+05        105527.000000    105527.000000   \n",
       "mean   9.473490e+05           529.814569         0.832521   \n",
       "min   -9.958676e+04           321.150000         0.000000   \n",
       "25%    7.904133e+05           513.150000         0.778309   \n",
       "50%    1.045234e+06           542.150000         0.899969   \n",
       "75%    1.121550e+06           553.150000         0.916647   \n",
       "max    1.524548e+06           597.150000         1.016633   \n",
       "std    2.658468e+05            39.830309         0.143739   \n",
       "\n",
       "       te_air_scav_rec_iso  pr_cyl_max_mv_iso  pr_cyl_comp_mv_iso  \\\n",
       "count         63500.000000       6.266600e+04        6.266600e+04   \n",
       "mean            304.499043       1.456122e+07        1.077643e+07   \n",
       "min             298.952784       4.027020e+06        4.056834e+06   \n",
       "25%             302.687664       1.300006e+07        9.345829e+06   \n",
       "50%             303.826959       1.551538e+07        1.157662e+07   \n",
       "75%             307.118440       1.628844e+07        1.227628e+07   \n",
       "max             310.687664       1.909924e+07        1.560651e+07   \n",
       "std               2.473322       2.465755e+06        2.250138e+06   \n",
       "\n",
       "          fr_eng_ecs  pr_air_scav_iso  engine_type_G80ME-C9.5-GI-LPSCR  \n",
       "count  105527.000000     62666.000000                         105527.0  \n",
       "mean        0.832848     99836.699333                              1.0  \n",
       "min         0.167429      3098.270339                              1.0  \n",
       "25%         0.777576     60206.960626                              1.0  \n",
       "50%         0.897077    106687.706718                              1.0  \n",
       "75%         0.917473    131524.664414                              1.0  \n",
       "max         1.020961    227660.755509                              1.0  \n",
       "std         0.142778     52343.895098                              0.0  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
